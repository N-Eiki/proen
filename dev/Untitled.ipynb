{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "warnings.simplefilter('ignore')\n",
    "sys.path.append('/Users/nagataeiki/.pyenv/versions/3.7.4/lib/python3.7/site-packages')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bad = pd.read_csv('../data/clean/cleaned_bad.csv')\n",
    "normal=pd.read_csv('../data/clean/cleaned_normal.csv')\n",
    "# hiniku_=pd.read_csv('../data/hiniku/hiniku_with_word.csv')\n",
    "hiniku = pd.read_csv(\"../data/clean/cleaned_hiniku.csv\")\n",
    "df = pd.read_csv('../data/clean/mount_all_data.csv')\n",
    "# df.drop('comment_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "badwordlist = pd.read_csv('../data/clean/mount_bad_list.csv')\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "tokenizer=Tokenizer()\n",
    "badwordlist_reading = []\n",
    "for word  in badwordlist.bad.values:\n",
    "    text=\"\"\n",
    "    for t in tokenizer.tokenize(word):\n",
    "        if t.reading==\"*\":\n",
    "            pass\n",
    "        else:\n",
    "            text+=t.reading\n",
    "    if len(text)>=1:\n",
    "        badwordlist_reading.append(text)\n",
    "# pd.DataFrame(badwordlist_reading).to_csv('../data/clean/badwordlist_reading.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# badwordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def train_and_pred(df, threshold=0.5):\n",
    "    df = df.copy()\n",
    "    df = df.dropna()\n",
    "    # testdf.target = testdf.target.apply(lambda x: 0 if x==0 else 1)#x==0(ニュートラル)の時0, その他は1\n",
    "    df.target = df.target.apply(lambda x: 0 if x==1 else 1)#x==1(悪口)の時0, その他は1 [0:悪口, 1:その他]\n",
    "    # testdf.target = testdf.target.apply(lambda x: 0 if x==2 else 1)#x==2(皮肉)の時0, その他は1\n",
    "    df.target.unique()\n",
    "    df.target.unique()\n",
    "    X = df.drop(\"target\",axis=1)#.drop('content', axis=1)\n",
    "    y=df.target\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)    \n",
    "    \n",
    "    svm = SVR()\n",
    "    svm.fit(x_train.drop(['content'], axis=1), y_train)\n",
    "    pred_train = svm.predict(x_train.drop(['content'], axis=1))\n",
    "    pred_test = svm.predict(x_test.drop(['content'], axis=1))\n",
    "\n",
    "    print(\"train\")\n",
    "\n",
    "    pred_train = [1 if x>threshold else 0 for x in pred_train]\n",
    "    pred_test = [1 if x>threshold else 0 for x in pred_test]\n",
    "    print(\"f1: \" ,f1_score(y_train, pred_train))\n",
    "    display(create_2x2_matrix(y_train, pred_train))\n",
    "    # print_2x2_miss_pred(y_train, pred_train,x_train)\n",
    "    print('------------------------------------------------------------------')\n",
    "    print('test')\n",
    "\n",
    "    print(\"f1: \",f1_score(y_test, pred_test))\n",
    "    display(create_2x2_matrix(y_test, pred_test))\n",
    "    train_miss = print_2x2_miss_pred(y_train, pred_train,x_train)\n",
    "    test_miss =  print_2x2_miss_pred(true_y=y_test, pred_y=pred_test,df=x_test)\n",
    "    return {\n",
    "        \"miss_train_df\":train_miss, \n",
    "        \"miss_test_df\":test_miss,\n",
    "        \"x_train\":x_train,\n",
    "        \"y_train\":y_train,\n",
    "        \"x_test\":x_test,\n",
    "        \"y_test\":y_test,\n",
    "        \"pred_train\":pred_train,\n",
    "        \"pred_test\":pred_test\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_2x2_matrix(true_y, pred_y):\n",
    "    matrix = np.zeros(4)\n",
    "\n",
    "    for t,p in zip(true_y, pred_y):\n",
    "        if t==0:\n",
    "            if p==0:matrix[0]+=1\n",
    "            if p==1:matrix[1]+=1\n",
    "        elif t==1:\n",
    "            if p==0:matrix[2]+=1\n",
    "            if p==1:matrix[3]+=1\n",
    "    return matrix.reshape(2,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_2x2_miss_pred(true_y, pred_y,df, test=True):\n",
    "    def print_str_label(num):\n",
    "        if num==1:return \"悪口\"\n",
    "        if num==0:return \"皮肉or その他\"\n",
    "        return np.nan\n",
    "\n",
    "    idx_arr = []\n",
    "    pred_judge=[]\n",
    "    true_judge=[]\n",
    "    col=[\"content\", \"pred_idx\", \"pred_label\",\"true_idx\", \"true_label\"]\n",
    "    returndf = pd.DataFrame(columns=col)\n",
    "    for i in range(len(df)):\n",
    "        if pred_y[i]!=true_y.values[i]:\n",
    "            tmpdf = pd.DataFrame(np.array([df.iloc[i].content, pred_y[i], print_str_label(pred_y[i]),\\\n",
    "                                            true_y.values[i], print_str_label(true_y.values[i])]).reshape(1,-1), \\\n",
    "                                              columns=col)\n",
    "            returndf = pd.concat([returndf, tmpdf])\n",
    "    return returndf\n",
    "\n",
    "\n",
    "def print_2x2_correct_pred(true_y, pred_y,df, test=True):\n",
    "    def print_str_label(num):\n",
    "        if num==1:return \"悪口\"\n",
    "        if num==0:return \"皮肉or その他\"\n",
    "        return np.nan\n",
    "\n",
    "    idx_arr = []\n",
    "    pred_judge=[]\n",
    "    true_judge=[]\n",
    "    col=[\"content\", \"pred_idx\", \"pred_label\",\"true_idx\", \"true_label\"]\n",
    "    returndf = pd.DataFrame(columns=col)\n",
    "    for i in range(len(df)):\n",
    "        if pred_y[i]==true_y.values[i]:\n",
    "            tmpdf = pd.DataFrame(np.array([df.iloc[i].content, pred_y[i], print_str_label(pred_y[i]),\\\n",
    "                                            true_y.values[i], print_str_label(true_y.values[i])]).reshape(1,-1), \\\n",
    "                                              columns=col)\n",
    "            returndf = pd.concat([returndf, tmpdf])\n",
    "    return returndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wakati_content(text):\n",
    "    wakati = []\n",
    "    for t in tokenizer.tokenize(text):\n",
    "        wakati.append(t.surface)\n",
    "    return wakati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "932it [00:02, 330.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "# data = pd.read_csv('../data/clean/mount_bad_list.csv')\n",
    "data = pd.read_csv(\"../data/clean/mount_all_data.csv\")\n",
    "data = data[data.type==1]\n",
    "wakati_arr = []\n",
    "for r in tqdm(data.iterrows()):\n",
    "    wakati = create_wakati_content(r[1].content)\n",
    "    wakati_arr.append(wakati)\n",
    "model = Word2Vec(wakati_arr, sg=1, size=100, window=5, min_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100001it [02:30, 665.38it/s]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/some_comment_data.csv')\n",
    "\n",
    "for r in tqdm(data.iterrows()):\n",
    "    wakati = create_wakati_content(r[1].content)\n",
    "    wakati_arr.append(wakati)\n",
    "model = Word2Vec(wakati_arr, sg=1, size=100, window=5, min_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1929it [00:14, 137.71it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>mophologics_num</th>\n",
       "      <th>bad_count_in_mophologic</th>\n",
       "      <th>simple_bad_flg</th>\n",
       "      <th>target</th>\n",
       "      <th>order</th>\n",
       "      <th>mophologic_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>なにこの糞ゲー</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[なに, この, 糞, ゲー]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ちょっと蛇足気味だな・・・</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[ちょっと, 蛇足, 気味, だ, な, ・, ・, ・]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         content  mophologics_num  bad_count_in_mophologic  simple_bad_flg  \\\n",
       "0        なにこの糞ゲー              4.0                      1.0               1   \n",
       "0  ちょっと蛇足気味だな・・・              8.0                      1.0               1   \n",
       "\n",
       "   target  order             mophologic_content  \n",
       "0       1      0                [なに, この, 糞, ゲー]  \n",
       "0       1      0  [ちょっと, 蛇足, 気味, だ, な, ・, ・, ・]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1929, 7)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "悪口ワードの含有\n",
    "皮肉ワードの含有\n",
    "ポジティブワードの含有\n",
    "\n",
    "[形態素解析した時の単語数],[単純に悪口単語が文章に含まれているのかのフラグ], [形態素ごとに現れる悪口数]\n",
    "[皮肉単語が含まれているかのフラグ],[形態素ごとに現れる皮肉数]\n",
    "[ポジティブな単語が含まれているかのフラグ], [形態素ごとに現れるポジティブ単語数]\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "# df = bad.copy()\n",
    "# df = pd.concat([hiniku_, normal])\n",
    "# df = pd.concat([bad, df])\n",
    "import sys\n",
    "import numpy as np\n",
    "from janome.tokenizer import Tokenizer\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "\n",
    "df = pd.read_csv('../data/clean/mount_all_data.csv')\n",
    "df.drop('comment_id', axis=1, inplace=True)\n",
    "tokenizer = Tokenizer()\n",
    "#悪口が含まれている数のカウント, 単に含まれているのかのフラグを返す\n",
    "def get_word_count(text, wordlist):\n",
    "    textlist = []\n",
    "    count=0\n",
    "    flg=0\n",
    "    for t in tokenizer.tokenize(text):\n",
    "        if t.surface in wordlist:\n",
    "            count+=1\n",
    "    for w in wordlist:\n",
    "        if w in text:\n",
    "            flg=1\n",
    "            return count, flg\n",
    "    \n",
    "    return count,flg\n",
    "\n",
    "\n",
    "def get_order_label(text):\n",
    "    for t in tokenizer.tokenize(text):\n",
    "        if t.infl_form[:2]==\"命令\":\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "def cos_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "\n",
    "'''\n",
    "###ここを実行することでword2vecのモデル作成\n",
    "from gensim.models import Word2Vec\n",
    "data = pd.read_csv('../data/some_comment_data.csv')\n",
    "newdata=pd.concat([pd.DataFrame(data.content), pd.DataFrame(df.content)])\n",
    "wakati_arr = []\n",
    "for r in tqdm(newdata.iterrows()):\n",
    "    wakati = create_wakati_content(r[1].content)\n",
    "    wakati_arr.append(wakadti)\n",
    "model = Word2Vec(wakati_arr, sg=1, size=100, window=5, min_count=1)\n",
    "'''\n",
    "\n",
    "def calc_cosine_similary(text,model,debug=False):\n",
    "    text_list = []\n",
    "    scores = {}\n",
    "\n",
    "    for t in tokenizer.tokenize(text):\n",
    "        text_list.append(t.surface)\n",
    "    for word in text_list:\n",
    "        try:\n",
    "            vector1 = model.wv[word]\n",
    "            scores[word] = []\n",
    "            for bad in bad_list:\n",
    "                try:\n",
    "                    vector2 = model.wv[bad]\n",
    "                    score = cos_similarity(vector1,vector2)\n",
    "                    scores[word].append(score)\n",
    "                except :\n",
    "                    pass\n",
    "        except:\n",
    "            pass\n",
    "    all_scores = []\n",
    "    for scores in scores.values():\n",
    "        all_scores +=scores\n",
    "    all_scores= np.array(all_scores)\n",
    "    typicalV = np.median(all_scores, axis=0)\n",
    "\n",
    "    if debug:\n",
    "        return scores\n",
    "    return typicalV\n",
    "\n",
    "\n",
    "def mophologicize(text):\n",
    "    words = []\n",
    "    for t in tokenizer.tokenize(text):\n",
    "        words.append(t.surface)    \n",
    "    return words\n",
    "\n",
    "\n",
    "#dfと悪口辞書を入れて新しい特徴量を含んだdfを返す\n",
    "def make_features(df, badwordlist, positivelist=np.nan, hinikulist=np.nan):\n",
    "#     col=[\"content\",\"mophologics_num\", \"bad_per_mophologic\", \"simple_bad_flg\",\"target\", \"hiniku_per_mophologic\",\\\n",
    "#          \"simple_hiniku_flg\", \"positive_per_mophologic\", \"simple_positive_flg\"]\n",
    "#     import gensim\n",
    "#     PATH=\"./gensimmodel/word2vec.gensim.model\"\n",
    "#     model = gensim.models.Word2Vec.load(PATH)\n",
    "    col=[\"content\",\"mophologics_num\", \"bad_count_in_mophologic\", \"simple_bad_flg\",\"target\",\"order\",\"mophologic_content\"]\n",
    "\n",
    "    basedf = pd.DataFrame(columns=col)\n",
    "    tokenizer = Tokenizer()\n",
    "    for r in tqdm(df.iterrows()):\n",
    "        text = str(r[1].content)\n",
    "        target = r[1].type\n",
    "        num = len(tokenizer.tokenize(text))\n",
    "        badcount,badflg = get_word_count(text, badwordlist)\n",
    "        orderlabel = get_order_label(text)\n",
    "        mophologic = mophologicize(text)\n",
    "#         hinikucount, hinikuflg = get_word_count(text, hinikulist)\n",
    "#         positivecount, positiveflg = get_word_count(text, positivelist)\n",
    "#         newdf = pd.DataFrame(np.array([text, num, badcount,badflg,target,\\\n",
    "#                                        hinikucount, hinikuflg, positivecount,\\\n",
    "#                                        positiveflg]).reshape(1,-1),columns=col)\n",
    "        newdf = pd.DataFrame(np.array([text, num, badcount,badflg,target, orderlabel,mophologic]).reshape(1,-1),columns=col)\n",
    "        basedf = pd.concat([basedf, newdf])\n",
    "\n",
    "    basedf[\"target\"] = basedf.apply(lambda x: int(x[\"target\"]), axis=1)\n",
    "#     basedf[\"comment_id\"] = basedf.index\n",
    "    basedf[\"bad_count_in_mophologic\"] = basedf.apply(lambda x: float(x[\"bad_count_in_mophologic\"]), axis=1)\n",
    "    basedf[\"mophologics_num\"] = basedf.apply(lambda x: float(x[\"mophologics_num\"]), axis=1)\n",
    "    basedf[\"order\"] = basedf.order.apply(lambda x: int(x))\n",
    "#     basedf[\"cosine_similar\"] = basedf.cosine_similar.apply(lambda x: float(x))\n",
    "    \n",
    "    return basedf\n",
    "df =make_features(df, list(badwordlist.bad.values))\n",
    "df = df.fillna(0.0)\n",
    "display(df.head(2))\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bad_word_list():\n",
    "    b_l=[]\n",
    "    #wor2vecの辞書にない単語の除外\n",
    "    for word in badwordlist.bad.values:\n",
    "        try:\n",
    "            a = model.wv[word]\n",
    "            b_l.append(word)\n",
    "        except:\n",
    "            pass\n",
    "    return b_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1929it [00:05, 342.48it/s]\n"
     ]
    }
   ],
   "source": [
    "col=[]\n",
    "for i in range(100):\n",
    "    col.append(\"f_\"+str(i))\n",
    "\n",
    "# def create_high_cosine_sim_vector_data(df):\n",
    "\n",
    "sandbox=pd.DataFrame(columns=col)\n",
    "for r in tqdm(df.iterrows()):\n",
    "    text = r[1].mophologic_content\n",
    "    vec_list=[]\n",
    "    flg=False\n",
    "    for t in text:\n",
    "            try:\n",
    "                vec = model.wv[t]\n",
    "                vec_list.append(vec)\n",
    "            except:\n",
    "                vec_list.append(np.zeros(100))\n",
    "    if flg:\n",
    "        pass\n",
    "    else:\n",
    "        vec_list = pd.DataFrame(np.array(vec_list), columns=col)\n",
    "\n",
    "        tmp = pd.DataFrame(pd.DataFrame(vec_list, columns=col).mean(axis=0)).T\n",
    "        sandbox = pd.concat([sandbox, tmp])\n",
    "        \n",
    "sandbox.insert(0, \"target\",df.target)\n",
    "sandbox.insert(1,\"content\",df.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "f1:  0.7109100050276521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[210., 528.],\n",
       "       [ 47., 707.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "test\n",
      "f1:  0.6735966735966735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 55., 139.],\n",
       "       [ 18., 162.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res=train_and_pred(sandbox,threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>content</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>...</th>\n",
       "      <th>f_90</th>\n",
       "      <th>f_91</th>\n",
       "      <th>f_92</th>\n",
       "      <th>f_93</th>\n",
       "      <th>f_94</th>\n",
       "      <th>f_95</th>\n",
       "      <th>f_96</th>\n",
       "      <th>f_97</th>\n",
       "      <th>f_98</th>\n",
       "      <th>f_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>なにこの糞ゲー</td>\n",
       "      <td>0.366073</td>\n",
       "      <td>0.112907</td>\n",
       "      <td>0.217428</td>\n",
       "      <td>-0.211347</td>\n",
       "      <td>-0.181887</td>\n",
       "      <td>-0.24082</td>\n",
       "      <td>0.429068</td>\n",
       "      <td>0.297758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028252</td>\n",
       "      <td>0.037143</td>\n",
       "      <td>0.009731</td>\n",
       "      <td>-0.014308</td>\n",
       "      <td>-0.137605</td>\n",
       "      <td>0.214183</td>\n",
       "      <td>-0.185315</td>\n",
       "      <td>0.030057</td>\n",
       "      <td>-0.173972</td>\n",
       "      <td>-0.279547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  content       f_0       f_1       f_2       f_3       f_4      f_5  \\\n",
       "0       1  なにこの糞ゲー  0.366073  0.112907  0.217428 -0.211347 -0.181887 -0.24082   \n",
       "\n",
       "        f_6       f_7  ...      f_90      f_91      f_92      f_93      f_94  \\\n",
       "0  0.429068  0.297758  ...  0.028252  0.037143  0.009731 -0.014308 -0.137605   \n",
       "\n",
       "       f_95      f_96      f_97      f_98      f_99  \n",
       "0  0.214183 -0.185315  0.030057 -0.173972 -0.279547  \n",
       "\n",
       "[1 rows x 102 columns]"
      ]
     },
     "execution_count": 555,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sandbox.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_2x2_miss_pred(true_y=res[\"y_test\"],pred_y=res[\"pred_test\"],df=res[\"x_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_2x2_correct_pred(true_y=res[\"y_test\"],pred_y=res[\"pred_test\"],df=res[\"x_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mean_cosine_sim_data(df):\n",
    "    b_l=create_bad_word_list()\n",
    "    base = pd.DataFrame(columns=np.array(b_l))\n",
    "    \n",
    "    for r in tqdm(df.iterrows()):\n",
    "        text = r[1].mophologic_content\n",
    "        ave_list=[]\n",
    "\n",
    "        for word in b_l:\n",
    "            try:\n",
    "                v1 = model.wv[word]\n",
    "                cos_list = []\n",
    "                for t in text:\n",
    "                        v2=model.wv[t]\n",
    "                        cos_list.append(cos_similarity(v1,v2))\n",
    "                        if word not in b_l:\n",
    "                            b_l.append(word)\n",
    "            except:\n",
    "                pass\n",
    "            ave_list.append(np.array(cos_list).mean())\n",
    "        tmp=pd.DataFrame(np.array(ave_list).reshape(1,-1), columns=b_l)\n",
    "        base=pd.concat([base, tmp])\n",
    "        \n",
    "    base[\"target\"] =df.target\n",
    "    base[\"content\"] = df.content\n",
    "    base = base.loc[:,base.columns[::-1]]\n",
    "\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1929it [00:46, 41.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>はげ</th>\n",
       "      <th>キモオタ</th>\n",
       "      <th>バカー</th>\n",
       "      <th>きしょい</th>\n",
       "      <th>クソゲー</th>\n",
       "      <th>クソムシ</th>\n",
       "      <th>きらい</th>\n",
       "      <th>gm</th>\n",
       "      <th>...</th>\n",
       "      <th>シカト</th>\n",
       "      <th>ゆとり</th>\n",
       "      <th>ダサい</th>\n",
       "      <th>死ね</th>\n",
       "      <th>KY</th>\n",
       "      <th>イタイ</th>\n",
       "      <th>ばっか</th>\n",
       "      <th>ヘタ</th>\n",
       "      <th>蛇足</th>\n",
       "      <th>糞</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>なにこの糞ゲー</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737712</td>\n",
       "      <td>0.585149</td>\n",
       "      <td>0.553066</td>\n",
       "      <td>0.503287</td>\n",
       "      <td>0.660441</td>\n",
       "      <td>0.685455</td>\n",
       "      <td>0.790680</td>\n",
       "      <td>0.616264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>0.808434</td>\n",
       "      <td>0.770303</td>\n",
       "      <td>0.681981</td>\n",
       "      <td>0.660041</td>\n",
       "      <td>0.673967</td>\n",
       "      <td>0.833161</td>\n",
       "      <td>0.694381</td>\n",
       "      <td>0.698025</td>\n",
       "      <td>0.844980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ちょっと蛇足気味だな・・・</td>\n",
       "      <td>1</td>\n",
       "      <td>0.670004</td>\n",
       "      <td>0.588808</td>\n",
       "      <td>0.553636</td>\n",
       "      <td>0.499966</td>\n",
       "      <td>0.630143</td>\n",
       "      <td>0.643968</td>\n",
       "      <td>0.664984</td>\n",
       "      <td>0.602853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588668</td>\n",
       "      <td>0.682783</td>\n",
       "      <td>0.706425</td>\n",
       "      <td>0.545869</td>\n",
       "      <td>0.592983</td>\n",
       "      <td>0.637162</td>\n",
       "      <td>0.679401</td>\n",
       "      <td>0.664682</td>\n",
       "      <td>0.654728</td>\n",
       "      <td>0.703167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>蛇足は同意</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833095</td>\n",
       "      <td>0.794032</td>\n",
       "      <td>0.705397</td>\n",
       "      <td>0.689864</td>\n",
       "      <td>0.834422</td>\n",
       "      <td>0.844973</td>\n",
       "      <td>0.823597</td>\n",
       "      <td>0.822670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774778</td>\n",
       "      <td>0.816561</td>\n",
       "      <td>0.865877</td>\n",
       "      <td>0.677959</td>\n",
       "      <td>0.799566</td>\n",
       "      <td>0.823735</td>\n",
       "      <td>0.757569</td>\n",
       "      <td>0.806733</td>\n",
       "      <td>0.857879</td>\n",
       "      <td>0.779104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         content  target        はげ      キモオタ       バカー      きしょい      クソゲー  \\\n",
       "0        なにこの糞ゲー       1  0.737712  0.585149  0.553066  0.503287  0.660441   \n",
       "0  ちょっと蛇足気味だな・・・       1  0.670004  0.588808  0.553636  0.499966  0.630143   \n",
       "0          蛇足は同意       1  0.833095  0.794032  0.705397  0.689864  0.834422   \n",
       "\n",
       "       クソムシ       きらい        gm  ...       シカト       ゆとり       ダサい        死ね  \\\n",
       "0  0.685455  0.790680  0.616264  ...  0.596774  0.808434  0.770303  0.681981   \n",
       "0  0.643968  0.664984  0.602853  ...  0.588668  0.682783  0.706425  0.545869   \n",
       "0  0.844973  0.823597  0.822670  ...  0.774778  0.816561  0.865877  0.677959   \n",
       "\n",
       "         KY       イタイ       ばっか        ヘタ        蛇足         糞  \n",
       "0  0.660041  0.673967  0.833161  0.694381  0.698025  0.844980  \n",
       "0  0.592983  0.637162  0.679401  0.664682  0.654728  0.703167  \n",
       "0  0.799566  0.823735  0.757569  0.806733  0.857879  0.779104  \n",
       "\n",
       "[3 rows x 154 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_sim_df = create_mean_cosine_sim_data(df)\n",
    "mean_sim_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "f1:  0.7098020280057943\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[156., 582.],\n",
       "       [ 19., 735.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "test\n",
      "f1:  0.6837944664031621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 41., 153.],\n",
       "       [  7., 173.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = train_and_pred(mean_sim_df,threshold=0.12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "なに 0.7348732\n",
      "この 0.5229607\n",
      "糞 0.86568695\n",
      "ゲー 0.82732815\n"
     ]
    }
   ],
   "source": [
    "v1 = model.wv[\"はげ\"]\n",
    "for t in text:\n",
    "    v2 = model.wv[t]\n",
    "    print(t, cos_similarity(v1,v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1929it [00:48, 39.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>はげ</th>\n",
       "      <th>キモオタ</th>\n",
       "      <th>バカー</th>\n",
       "      <th>きしょい</th>\n",
       "      <th>クソゲー</th>\n",
       "      <th>クソムシ</th>\n",
       "      <th>きらい</th>\n",
       "      <th>gm</th>\n",
       "      <th>...</th>\n",
       "      <th>シカト</th>\n",
       "      <th>ゆとり</th>\n",
       "      <th>ダサい</th>\n",
       "      <th>死ね</th>\n",
       "      <th>KY</th>\n",
       "      <th>イタイ</th>\n",
       "      <th>ばっか</th>\n",
       "      <th>ヘタ</th>\n",
       "      <th>蛇足</th>\n",
       "      <th>糞</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>なにこの糞ゲー</td>\n",
       "      <td>1</td>\n",
       "      <td>0.865687</td>\n",
       "      <td>0.704362</td>\n",
       "      <td>0.690638</td>\n",
       "      <td>0.628814</td>\n",
       "      <td>0.795038</td>\n",
       "      <td>0.815677</td>\n",
       "      <td>0.896863</td>\n",
       "      <td>0.726885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.704689</td>\n",
       "      <td>0.929999</td>\n",
       "      <td>0.882585</td>\n",
       "      <td>0.820817</td>\n",
       "      <td>0.778329</td>\n",
       "      <td>0.792534</td>\n",
       "      <td>0.958242</td>\n",
       "      <td>0.817534</td>\n",
       "      <td>0.830522</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ちょっと蛇足気味だな・・・</td>\n",
       "      <td>1</td>\n",
       "      <td>0.946054</td>\n",
       "      <td>0.952036</td>\n",
       "      <td>0.852232</td>\n",
       "      <td>0.798920</td>\n",
       "      <td>0.979366</td>\n",
       "      <td>0.966861</td>\n",
       "      <td>0.911843</td>\n",
       "      <td>0.970934</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893810</td>\n",
       "      <td>0.919892</td>\n",
       "      <td>0.976364</td>\n",
       "      <td>0.761640</td>\n",
       "      <td>0.930671</td>\n",
       "      <td>0.938139</td>\n",
       "      <td>0.865346</td>\n",
       "      <td>0.919833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         content  target        はげ      キモオタ       バカー      きしょい      クソゲー  \\\n",
       "0        なにこの糞ゲー       1  0.865687  0.704362  0.690638  0.628814  0.795038   \n",
       "0  ちょっと蛇足気味だな・・・       1  0.946054  0.952036  0.852232  0.798920  0.979366   \n",
       "\n",
       "       クソムシ       きらい        gm  ...       シカト       ゆとり       ダサい        死ね  \\\n",
       "0  0.815677  0.896863  0.726885  ...  0.704689  0.929999  0.882585  0.820817   \n",
       "0  0.966861  0.911843  0.970934  ...  0.893810  0.919892  0.976364  0.761640   \n",
       "\n",
       "         KY       イタイ       ばっか        ヘタ        蛇足         糞  \n",
       "0  0.778329  0.792534  0.958242  0.817534  0.830522  1.000000  \n",
       "0  0.930671  0.938139  0.865346  0.919833  1.000000  0.886566  \n",
       "\n",
       "[2 rows x 154 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_the_highest_cosine_sim_data(df):\n",
    "    b_l = create_bad_word_list()\n",
    "    base = pd.DataFrame(columns=np.array(b_l))\n",
    "    \n",
    "    for r in tqdm(df.iterrows()):\n",
    "        text = r[1].mophologic_content\n",
    "        highest_list=[]\n",
    "\n",
    "        for word in b_l:\n",
    "            try:\n",
    "                v1 = model.wv[word]\n",
    "                cos_list = []\n",
    "                for t in text:\n",
    "                        v2=model.wv[t]\n",
    "                        cos_list.append(cos_similarity(v1,v2))\n",
    "                        if word not in b_l:\n",
    "                            b_l.append(word)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                highest_list.append(np.array(cos_list).max())\n",
    "            except:\n",
    "                highest_list.append(np.nan)\n",
    "        tmp=pd.DataFrame(np.array(highest_list).reshape(1,-1), columns=b_l)\n",
    "        base=pd.concat([base, tmp])\n",
    "        \n",
    "    base[\"target\"] =df.target\n",
    "    base[\"content\"] = df.content\n",
    "    base = base.loc[:,base.columns[::-1]]\n",
    "    return base\n",
    "\n",
    "high_sim_df = create_the_highest_cosine_sim_data(df)\n",
    "high_sim_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "f1:  0.7479674796747967\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[337., 401.],\n",
       "       [ 64., 690.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------\n",
      "test\n",
      "f1:  0.7400881057268723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 88., 106.],\n",
       "       [ 12., 168.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = train_and_pred(high_sim_df,threshold=0.32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testdf = base.copy()\n",
    "# testdf = testdf.dropna()\n",
    "# # testdf.target = testdf.target.apply(lambda x: 0 if x==0 else 1)#x==0(ニュートラル)の時0, その他は1\n",
    "# testdf.target = testdf.target.apply(lambda x: 0 if x==1 else 1)#x==1(悪口)の時0, その他は1 [0:悪口, 1:その他]\n",
    "# # testdf.target = testdf.target.apply(lambda x: 0 if x==2 else 1)#x==2(皮肉)の時0, その他は1\n",
    "# testdf.target.unique()\n",
    "# testdf.target.unique()\n",
    "# X = testdf.drop(\"target\",axis=1)#.drop('content', axis=1)\n",
    "# y=testdf.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# 1対1で予測をする時\n",
    "# '''\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# def vectorize(x_train,x_test, vec):\n",
    "#     x_train_vec = vec.fit_transform(x_train.content)\n",
    "#     x_test_vec = vec.transform(x_test.content)\n",
    "    \n",
    "#     x_train_vec = pd.DataFrame(x_train_vec.todense())\n",
    "#     x_test_vec = pd.DataFrame(x_test_vec.todense())\n",
    "#     return x_train_vec,x_test_vec\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tra,tes = train_and_pred(sandbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "def train_and_pred(df, threshold=0.5):\n",
    "    df = df.copy()\n",
    "    df = df.dropna()\n",
    "    # testdf.target = testdf.target.apply(lambda x: 0 if x==0 else 1)#x==0(ニュートラル)の時0, その他は1\n",
    "    df.target = df.target.apply(lambda x: 0 if x==1 else 1)#x==1(悪口)の時0, その他は1 [0:悪口, 1:その他]\n",
    "    # testdf.target = testdf.target.apply(lambda x: 0 if x==2 else 1)#x==2(皮肉)の時0, その他は1\n",
    "    df.target.unique()\n",
    "    df.target.unique()\n",
    "    X = df.drop(\"target\",axis=1)#.drop('content', axis=1)\n",
    "    y=df.target\n",
    "\n",
    "    \n",
    "    svm = SVR()\n",
    "    svm.fit(x_train.drop(['content'], axis=1), y_train)\n",
    "    pred_train = svm.predict(x_train.drop(['content'], axis=1))\n",
    "    pred_test = svm.predict(x_test.drop(['content'], axis=1))\n",
    "\n",
    "    print(\"train\")\n",
    "\n",
    "    pred_train = [1 if x>threshold else 0 for x in pred_train]\n",
    "    pred_test = [1 if x>threshold else 0 for x in pred_test]\n",
    "    print(\"f1: \" ,f1_score(y_train, pred_train))\n",
    "    display(create_2x2_matrix(y_train, pred_train))\n",
    "    # print_2x2_miss_pred(y_train, pred_train,x_train)\n",
    "    print('------------------------------------------------------------------')\n",
    "    print('test')\n",
    "\n",
    "    print(\"f1: \",f1_score(y_test, pred_test))\n",
    "    display(create_2x2_matrix(y_test, pred_test))\n",
    "    train_miss = print_2x2_miss_pred(y_train, pred_train,x_train)\n",
    "    test_miss =  print_2x2_miss_pred(true_y=y_test, pred_y=pred_test,df=x_test)\n",
    "    return {\n",
    "        \"miss_train_df\":train_miss, \n",
    "        \"miss_test_df\":test_miss,\n",
    "        \"x_train\":x_train,\n",
    "        \"y_train\":y_train,\n",
    "        \"x_test\":x_test,\n",
    "        \"y_test\":y_test,\n",
    "        \"pred_train\":pred_train,\n",
    "        \"pred_test\":pred_test\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVR\n",
    "# svm = SVR()\n",
    "\n",
    "# # svm.fit(x_train_vec, y_train)\n",
    "# # pred_train = svm.predict(x_train_vec)\n",
    "# # pred_test = svm.predict(x_test_vec)\n",
    "\n",
    "\n",
    "# # svm.fit(x_train.drop(['content',\"cosine_similary\"], axis=1), y_train)\n",
    "# # pred_train = svm.predict(x_train.drop(['content',\"cosine_similary\"], axis=1))\n",
    "# # pred_test = svm.predict(x_test.drop(['content',\"cosine_similary\"], axis=1))\n",
    "\n",
    "\n",
    "# svm.fit(x_train.drop(['content'], axis=1), y_train)\n",
    "# pred_train = svm.predict(x_train.drop(['content'], axis=1))\n",
    "# pred_test = svm.predict(x_test.drop(['content'], axis=1))\n",
    "\n",
    "# print(\"train\")\n",
    "\n",
    "# pred_train = [1 if x>0.899 else 0 for x in pred_train]\n",
    "# pred_test = [1 if x>0.899 else 0 for x in pred_test]\n",
    "# print(f1_score(y_train, pred_train))\n",
    "# display(create_2x2_matrix(y_train, pred_train))\n",
    "# # print_2x2_miss_pred(y_train, pred_train,x_train)\n",
    "# print('------------------------------------------------------------------')\n",
    "# print('test')\n",
    "\n",
    "# print(f1_score(y_test, pred_test))\n",
    "# display(create_2x2_matrix(y_test, pred_test))\n",
    "# # print_2x2_miss_pred(true_y=y_test, pred_y=pred_test,df=x_test).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_miss = print_2x2_miss_pred(y_train, pred_train,x_train)\n",
    "test_miss =  print_2x2_miss_pred(true_y=y_test, pred_y=pred_test,df=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_df = print_2x2_pred_true(y_train, pred_train,x_train)\n",
    "test_pred_df =  print_2x2_pred_true(true_y=y_test, pred_y=pred_test,df=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "0.8698839340256568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[618., 130.],\n",
       "       [ 83., 712.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "0.919315403422983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[165.,  19.],\n",
       "       [ 14., 188.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "gbm = lgb.LGBMClassifier()\n",
    "x_train.simple_bad_flg = x_train.simple_bad_flg.apply(lambda x: int(x))\n",
    "x_test.simple_bad_flg = x_test.simple_bad_flg.apply(lambda x: int(x))\n",
    "x_test.cosine_similar = x_test.cosine_similar.apply(lambda x: float(x))\n",
    "\n",
    "\n",
    "gbm.fit(x_train.drop('content',axis=1),y_train)\n",
    "pred_train = gbm.predict(x_train.drop('content',axis=1))\n",
    "pred_test = gbm.predict(x_test.drop('content',axis=1))\n",
    "\n",
    "# gbm.fit(x_train.drop(['content',\"cosine_similary\"],axis=1),y_train)\n",
    "# pred_train = gbm.predict(x_train.drop(['content',\"cosine_similary\"],axis=1))\n",
    "# pred_test = gbm.predict(x_test.drop(['content',\"cosine_similary\"],axis=1))\n",
    "'''\n",
    "train\n",
    "0.8698839340256568\n",
    "array([[618., 130.],\n",
    "       [ 83., 712.]])\n",
    "test\n",
    "0.919315403422983\n",
    "array([[165.,  19.],\n",
    "       [ 14., 188.]])\n",
    "'''\n",
    "\n",
    "# gbm.fit(x_train_vec, y_train)\n",
    "# pred_train = gbm.predict(x_train_vec)\n",
    "# pred_test = gbm.predict(x_test_vec)\n",
    "\n",
    "\n",
    "print(\"train\")\n",
    "print(f1_score(y_train, pred_train))\n",
    "display(create_2x2_matrix(y_train, pred_train))\n",
    "# print_2x2_miss_pred(y_train, pred_train,x_train).head()\n",
    "print('test')\n",
    "\n",
    "print(f1_score(y_test, pred_test))\n",
    "display(create_2x2_matrix(y_test, pred_test))\n",
    "# print_2x2_miss_pred(true_y=y_test, pred_y=pred_test,df=x_test).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x134341670>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgb.plot_importance(gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# 1対その他での学習\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.multiclass import OneVsRestClassifier\n",
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "# def vectorize(x_train,x_test, vec):\n",
    "#     x_train_vec = vec.fit_transform(x_train.content)\n",
    "#     x_test_vec = vec.transform(x_test.content)\n",
    "    \n",
    "#     x_train_vec = pd.DataFrame(x_train_vec.todense())\n",
    "#     x_test_vec = pd.DataFrame(x_test_vec.todense())\n",
    "    \n",
    "#     x_train_vec[\"comment_id\"]=x_train.comment_id.values\n",
    "#     x_test_vec[\"comment_id\"]=x_test.comment_id.values\n",
    "    \n",
    "#     return x_train_vec,x_test_vec\n",
    "\n",
    "\n",
    "\n",
    "# def train_and_predict(df):\n",
    "\n",
    "#     X = df.drop(\"target\",axis=1)\n",
    "#     y = df.target\n",
    "\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "    \n",
    "#     vec = TfidfVectorizer()\n",
    "#     x_train_vec, x_test_vec = vectorize(x_train, x_test, vec)\n",
    "#     train_content = pd.DataFrame(x_train.content.values, columns=[\"content\"])\n",
    "#     test_content  = pd.DataFrame(x_test.content.values, columns=[\"content\"])\n",
    "#     x_train.drop([\"content\"],axis=1,inplace=True)\n",
    "#     x_test.drop([\"content\"],axis=1,inplace=True)\n",
    "#     new_x_train = x_train.merge(x_train_vec, on=\"comment_id\")#.drop('comment_id',axis=1)\n",
    "#     new_x_test  = x_test.merge(x_test_vec, on=\"comment_id\")#.drop('comment_id',axis=1)\n",
    "#     new_x_train.drop('comment_id', axis=1, inplace=True)\n",
    "#     new_x_test.drop('comment_id', axis=1, inplace=True)\n",
    "#     x_train.drop([\"comment_id\"],axis=1,inplace=True)\n",
    "#     x_test.drop([\"comment_id\"],axis=1,inplace=True)\n",
    "\n",
    "#     svm = SVC(C=1.0, random_state=42)\n",
    "#     vec_model = OneVsRestClassifier(svm)\n",
    "#     vec_model.fit(new_x_train, y_train)\n",
    "#     model = OneVsRestClassifier(svm)\n",
    "#     model.fit(x_train, y_train)\n",
    "#     print('fin')\n",
    "\n",
    "#     return {\n",
    "#         \"pred_train_with_vec\":  vec_model.predict(new_x_train),\n",
    "#         \"pred_test_with_vec\": vec_model.predict(new_x_test),\n",
    "#         \"pred_train\":model.predict(x_train),\n",
    "#         \"pred_test\":model.predict(x_test),\n",
    "#         \"x_train\":x_train,\n",
    "#         \"new_x_train\":new_x_train,\n",
    "#         \"y_train\":y_train,\n",
    "#         \"new_x_test\":new_x_test,\n",
    "#         \"x_test\":x_test,\n",
    "#         \"y_test\":y_test,\n",
    "#         \"train_content\":train_content,\n",
    "#         \"test_content\":test_content,\n",
    "# #         \"x_train_vec\":x_train_vec,\n",
    "# #         \"x_test_vec\":x_test_vec\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import recall_score\n",
    "# from sklearn.metrics import precision_score\n",
    "# import numpy as np\n",
    "# '''\n",
    "# mxm,ここでは3x3のマトリックスを作成する\n",
    "# そこからf1値を計算する（同ディレクトリの画像参照）\n",
    "# '''\n",
    "\n",
    "# def create_3x3_matrix(true_y, pred_y):\n",
    "#     matrix = np.zeros(9)\n",
    "\n",
    "#     for t,p in zip(true_y, pred_y):\n",
    "#         if t==0:\n",
    "#             if p==0:matrix[0]+=1\n",
    "#             if p==1:matrix[1]+=1\n",
    "#             if p==2:matrix[2]+=1\n",
    "#         elif t==1:\n",
    "#             if p==0:matrix[3]+=1\n",
    "#             if p==1:matrix[4]+=1\n",
    "#             if p==2:matrix[5]+=1\n",
    "#         elif t==2:\n",
    "#             if p==0:matrix[6]+=1\n",
    "#             if p==1:matrix[7]+=1\n",
    "#             if p==2:matrix[8]+=1\n",
    "\n",
    "#     return matrix.reshape(3,3)\n",
    "# # matrix=create_3x3_matrix(y_train, pred_train)\n",
    "# # matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.to_csv('../data/clean/mount_data.csv', index=False)\n",
    "# df1.to_excel('../data/clean/mount_data.xlsx', index=False)\n",
    "# df1 = pd.read_excel('../data/clean/mount_data.xlsx')\n",
    "# df1 = df1.dropna()\n",
    "# df1[\"type\"]=df1.target\n",
    "# df1 = make_bad_feature(df1, badwordlist=badwordlist, positivelist=positivelist, hinikulist=hinikulist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1[df1.target==0].shape[0], df1[df1.target==1].shape[0],df1[df1.target==2].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# predのキー\n",
    "# dict_keys(['pred_train', 'pred_test', 'x_train', 'new_x_train', 'y_train',\\\n",
    "# 'new_x_test', 'x_test', 'y_test', 'train_content', 'test_content'])\n",
    "# '''\n",
    "\n",
    "# def print_3x3miss_pred(pred, test=True, true_y=np.nan, pred_y=np.nan,df=np.nan):\n",
    "#     if test:\n",
    "#         true_y = pred[\"y_test\"]\n",
    "#         pred_y = pred[\"pred_test\"]\n",
    "#         df     = pred[\"test_content\"]\n",
    "#     else:\n",
    "#         true_y = pred[\"y_train\"]\n",
    "#         pred_y = pred[\"pred_train\"]\n",
    "#         df     = pred[\"train_content\"]\n",
    "\n",
    "\n",
    "#     idx_arr = []\n",
    "#     pred_judge=[]\n",
    "#     true_judge=[]\n",
    "#     for i in range(len(pred_y)):\n",
    "#         if pred_y[i]!=true_y.values[i]:\n",
    "# #             print(pred[i], true_y.values[i])\n",
    "#             idx_arr.append(i)\n",
    "#             pred_judge.append(pred_y[i])\n",
    "#             true_judge.append(true_y.values[i])\n",
    "\n",
    "#     def print_str_label(num):\n",
    "#         if num==0:return \"ニュートラル\"\n",
    "#         if num==1:return \"悪口\"\n",
    "#         if num==2:return \"皮肉\"\n",
    "#         return np.nan\n",
    "    \n",
    "#     col=[\"content\",\"true_label_id\",\"true_label\",\"pred_label_id\",\"pred_label\"]\n",
    "#     miss_data = pd.DataFrame(columns=col)\n",
    "#     for i,idx in enumerate(idx_arr):\n",
    "#         tmpdf = pd.DataFrame(np.array([df.iloc[idx].content, true_judge[i],\\\n",
    "#                                           print_str_label(true_judge[i]), pred_judge[i],\\\n",
    "#                                         print_str_label(pred_judge[i])]).reshape(1,-1),columns=col)\n",
    "#         miss_data = pd.concat([miss_data, tmpdf])\n",
    "        \n",
    "# #             display(df.iloc[idx].content)\n",
    "# #             print('true label  *',true_judge[i] , (print_str_label(true_judge[i])))\n",
    "# #             print('pred label  *',pred_judge[i], (print_str_label(pred_judge[i])))\n",
    "# #             print(\"------------------------------------------------------------------------------------\")\n",
    "        \n",
    "#     print(miss_data.shape)\n",
    "#     return miss_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n他のベクトル変換の例\\n\\nx_train,x_test, y_train, y_test = train_test_split(content, target, random_state=42)\\n\\n・バイナリ\\nvec = CountVectorizer(binary=True)\\ntrain_and_val(x_train, x_test, y_train, y_test, vec)\\n\\n・カウント\\nprint('count')\\nvec = CountVectorizer(binary=False)\\ntrain_and_val(x_train, x_test, y_train, y_test, vec)\\n\\n\\n・TfIdf\\nvec = TfidfVectorizer()\\nvectorize(x_train, x_test, y_train, y_test, vec)\\n\\n・bigram\\nvec = TfidfVectorizer(ngram_range=(1,3))\\ntrain_and_val(x_train, x_test, y_train, y_test, vec)\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "他のベクトル変換の例\n",
    "\n",
    "x_train,x_test, y_train, y_test = train_test_split(content, target, random_state=42)\n",
    "\n",
    "・バイナリ\n",
    "vec = CountVectorizer(binary=True)\n",
    "train_and_val(x_train, x_test, y_train, y_test, vec)\n",
    "\n",
    "・カウント\n",
    "print('count')\n",
    "vec = CountVectorizer(binary=False)\n",
    "train_and_val(x_train, x_test, y_train, y_test, vec)\n",
    "\n",
    "\n",
    "・TfIdf\n",
    "vec = TfidfVectorizer()\n",
    "vectorize(x_train, x_test, y_train, y_test, vec)\n",
    "\n",
    "・bigram\n",
    "vec = TfidfVectorizer(ngram_range=(1,3))\n",
    "train_and_val(x_train, x_test, y_train, y_test, vec)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>mophologics_num</th>\n",
       "      <th>bad_per_mophologic</th>\n",
       "      <th>simple_bad_flg</th>\n",
       "      <th>target</th>\n",
       "      <th>hiniku_per_mophologic</th>\n",
       "      <th>simple_hiniku_flg</th>\n",
       "      <th>positive_per_mophologic</th>\n",
       "      <th>simple_positive_flg</th>\n",
       "      <th>comment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ガイジ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>くどい</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  content  mophologics_num  bad_per_mophologic  simple_bad_flg  target  \\\n",
       "0     ガイジ                1                   1               1       1   \n",
       "1     くどい                1                   1               1       1   \n",
       "\n",
       "   hiniku_per_mophologic  simple_hiniku_flg  positive_per_mophologic  \\\n",
       "0                      0                  0                        0   \n",
       "1                      0                  0                        0   \n",
       "\n",
       "   simple_positive_flg  comment_id  \n",
       "0                    0           0  \n",
       "1                    0           1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = train_and_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no vectorize train\n",
      "[[517.  22.  53.]\n",
      " [252. 448.  46.]\n",
      " [191.  49. 134.]]\n",
      "{'recalls': array([0.87331081, 0.60053619, 0.35828877]), 'precisions': array([0.53854167, 0.86319846, 0.5751073 ]), 'f1': 0.6339142135942205}\n",
      "\n",
      "\n",
      "no vectoizer test\n",
      "[[129.  12.  14.]\n",
      " [ 64. 106.  16.]\n",
      " [ 47.  11.  29.]]\n",
      "{'recalls': array([0.83225806, 0.56989247, 0.33333333]), 'precisions': array([0.5375    , 0.82170543, 0.49152542]), 'f1': 0.5970851886381953}\n",
      "\n",
      "\n",
      "vectorize train\n",
      "[[527.  19.  46.]\n",
      " [246. 482.  18.]\n",
      " [187.  38. 149.]]\n",
      "{'recalls': array([0.8902027 , 0.6461126 , 0.39839572]), 'precisions': array([0.54895833, 0.89424861, 0.69953052]), 'f1': 0.6778058715586218}\n",
      "\n",
      "\n",
      "vectorize test\n",
      "[[130.   9.  16.]\n",
      " [ 65. 104.  17.]\n",
      " [ 45.  11.  31.]]\n",
      "{'recalls': array([0.83870968, 0.55913978, 0.35632184]), 'precisions': array([0.54166667, 0.83870968, 0.484375  ]), 'f1': 0.6025906257243245}\n"
     ]
    }
   ],
   "source": [
    "# print(\"no vectorize train\")\n",
    "# matrix=create_3x3_matrix(pred[\"y_train\"], pred[\"pred_train\"])\n",
    "# print(matrix)\n",
    "# print(calc_scores(matrix))\n",
    "# print()\n",
    "# print()\n",
    "# print('no vectoizer test')\n",
    "# matrix=create_3x3_matrix(pred[\"y_test\"], pred[\"pred_test\"])\n",
    "# print(matrix)\n",
    "# print(calc_scores(matrix))\n",
    "# print()\n",
    "# print()\n",
    "\n",
    "# print(\"vectorize train\")\n",
    "# matrix=create_3x3_matrix(pred[\"y_train\"], pred[\"pred_train_with_vec\"])\n",
    "# print(matrix)\n",
    "# print(calc_scores(matrix))\n",
    "# print()\n",
    "# print()\n",
    "# print('vectorize test')\n",
    "# matrix=create_3x3_matrix(pred[\"y_test\"], pred[\"pred_test_with_vec\"])\n",
    "# print(matrix)\n",
    "# print(calc_scores(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6742897"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1 = model.wv[\"この\"]\n",
    "v2 = model.wv[\"殺す\"]\n",
    "\n",
    "cos_similarity(v1,v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
