{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bad = pd.read_csv('../data/bad/bad.csv')\n",
    "normal=pd.read_csv('../data/neautral/neutral.csv')\n",
    "hiniku_=pd.read_csv('../data/hiniku/hiniku_with_word.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positivelist = list(hiniku_.dropna().positiveword.values)\n",
    "hinikulist = list(hiniku_.dropna().hinikuword.values)\n",
    "badwordlist = list(bad.word)#悪口単語をリストで抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "750it [00:06, 109.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "悪口ワードの含有\n",
    "皮肉ワードの含有\n",
    "ポジティブワードの含有\n",
    "\n",
    "[形態素解析した時の単語数],[単純に悪口単語が文章に含まれているのかのフラグ], [形態素ごとに現れる悪口数]\n",
    "[皮肉単語が含まれているかのフラグ],[形態素ごとに現れる皮肉数]\n",
    "[ポジティブな単語が含まれているかのフラグ], [形態素ごとに現れるポジティブ単語数]\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "# df = bad.copy()\n",
    "df = pd.concat([hiniku_, normal])\n",
    "df = pd.concat([bad, df])\n",
    "import sys\n",
    "sys.path.append('/Users/nagataeiki/.pyenv/versions/3.7.4/lib/python3.7/site-packages')\n",
    "import numpy as np\n",
    "from janome.tokenizer import Tokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "#悪口が含まれている数のカウント, 単に含まれているのかのフラグを返す\n",
    "def get_word_count(text, wordlist):\n",
    "    textlist = []\n",
    "    count=0\n",
    "    flg=0\n",
    "    for t in tokenizer.tokenize(text):\n",
    "        if t.surface in wordlist:\n",
    "            count+=1\n",
    "    for w in wordlist:\n",
    "        if w in text:\n",
    "            flg=1\n",
    "            return count, flg\n",
    "    \n",
    "    return count,flg\n",
    "\n",
    "\n",
    "#dfと悪口辞書を入れて新しい特徴量を含んだdfを返す\n",
    "def make_bad_feature(df, badwordlist, positivelist, hinikulist):\n",
    "    col=[\"content\",\"mophologics_num\", \"bad_per_mophologic\", \"simple_bad_flg\",\"target\", \"hiniku_per_mophologic\",\\\n",
    "         \"simple_hiniku_flg\", \"positive_per_mophologic\", \"simple_positive_flg\"]\n",
    "    basedf = pd.DataFrame(columns=col)\n",
    "    tokenizer = Tokenizer()\n",
    "    for r in tqdm(df.iterrows()):\n",
    "        text = str(r[1].content)\n",
    "        target = r[1].type\n",
    "        num = len(tokenizer.tokenize(text))\n",
    "        badcount,badflg = get_word_count(text, badwordlist)\n",
    "        hinikucount, hinikuflg = get_word_count(text, hinikulist)\n",
    "        positivecount, positiveflg = get_word_count(text, positivelist)\n",
    "        newdf = pd.DataFrame(np.array([text, num, badcount,badflg,target,\\\n",
    "                                       hinikucount, hinikuflg, positivecount,\\\n",
    "                                       positiveflg]).reshape(1,-1),columns=col)\n",
    "        basedf = pd.concat([basedf, newdf])\n",
    "\n",
    "    basedf[\"target\"] = basedf.apply(lambda x: int(x[\"target\"]), axis=1)\n",
    "    return basedf\n",
    "df =make_bad_feature(df, badwordlist, positivelist, hinikulist)\n",
    "df.head(2)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiniku_ = pd.read_csv('../data/hiniku/hiniku_with_word.csv')\n",
    "\n",
    "# col=[\"content\",\"mophologics_num\", \"bad_word_num\", \"simple_bad_flg\",\"target\", \"hinikuword\", \"positiveword\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# 1対1で予測をする時\n",
    "# '''\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import f1_score\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "# svm = SVC(C=1.0, random_state=42)\n",
    "# svm.fit(x_train, y_train)\n",
    "\n",
    "# pred_train = svm.predict(x_train)\n",
    "# pred_test = svm.predict(x_test)\n",
    "# print(f1_score(y_train, pred_train))\n",
    "# print(f1_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1対その他での学習\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "def vectorize(x_train,x_test, vec):\n",
    "    x_train_vec = vec.fit_transform(x_train.content)\n",
    "    x_test_vec = vec.transform(x_test.content)\n",
    "    \n",
    "    x_train_vec = pd.DataFrame(x_train_vec.todense())\n",
    "    x_test_vec = pd.DataFrame(x_test_vec.todense())\n",
    "    \n",
    "    x_train_vec[\"comment_id\"]=x_train.comment_id.values\n",
    "    x_test_vec[\"comment_id\"]=x_test.comment_id.values\n",
    "    \n",
    "    return x_train_vec,x_test_vec\n",
    "\n",
    "\n",
    "\n",
    "def train_and_predict(df):\n",
    "\n",
    "    X = df.drop(\"target\",axis=1)\n",
    "    y = df.target\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "    \n",
    "    vec = TfidfVectorizer()\n",
    "    x_train_vec, x_test_vec = vectorize(x_train, x_test, vec)\n",
    "    train_content = pd.DataFrame(x_train.content.values, columns=[\"content\"])\n",
    "    test_content  = pd.DataFrame(x_test.content.values, columns=[\"content\"])\n",
    "    x_train.drop(\"content\",axis=1,inplace=True)\n",
    "    x_test.drop(\"content\",axis=1,inplace=True)\n",
    "    new_x_train = x_train.merge(x_train_vec, on=\"comment_id\")#.drop('content',axis=1)\n",
    "    new_x_test  = x_test.merge(x_test_vec, on=\"comment_id\")#.drop('content',axis=1)\n",
    "    svm = SVC(C=1.0, random_state=42)\n",
    "    model = OneVsRestClassifier(svm)\n",
    "    model.fit(new_x_train, y_train)\n",
    "    print('fin')\n",
    "\n",
    "    return {\n",
    "        \"pred_train\":  model.predict(new_x_train),\n",
    "        \"pred_test\": model.predict(new_x_test),\n",
    "        \"x_train\":x_train,\n",
    "        \"new_x_train\":new_x_train,\n",
    "        \"y_train\":y_train,\n",
    "        \"new_x_test\":new_x_test,\n",
    "        \"x_test\":x_test,\n",
    "        \"y_test\":y_test,\n",
    "        \"train_content\":train_content,\n",
    "        \"test_content\":test_content,\n",
    "#         \"x_train_vec\":x_train_vec,\n",
    "#         \"x_test_vec\":x_test_vec\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "'''\n",
    "mxm,ここでは3x3のマトリックスを作成する\n",
    "そこからf1値を計算する（同ディレクトリの画像参照）\n",
    "'''\n",
    "\n",
    "def create_3x3_matrix(true_y, pred_y):\n",
    "    matrix = np.zeros(9)\n",
    "\n",
    "    for t,p in zip(true_y, pred_y):\n",
    "        if t==0:\n",
    "            if p==0:matrix[0]+=1\n",
    "            if p==1:matrix[1]+=1\n",
    "            if p==2:matrix[2]+=1\n",
    "        elif t==1:\n",
    "            if p==0:matrix[3]+=1\n",
    "            if p==1:matrix[4]+=1\n",
    "            if p==2:matrix[5]+=1\n",
    "        elif t==2:\n",
    "            if p==0:matrix[6]+=1\n",
    "            if p==1:matrix[7]+=1\n",
    "            if p==2:matrix[8]+=1\n",
    "\n",
    "    return matrix.reshape(3,3)\n",
    "# matrix=create_3x3_matrix(y_train, pred_train)\n",
    "# matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "使用例:\n",
    " calc_scores(matrix)\n",
    " \n",
    "出力例:\n",
    "{'recalls': array([0.31693989, 0.34710744, 0.28      ]),\n",
    " 'Precisions': array([0.28292683, 0.41176471, 0.2565445 ]),\n",
    " 'f1': 0.31587601668402826}\n",
    "'''\n",
    "\n",
    "def calc_scores(matrix):\n",
    "    Recalls = np.zeros(3)\n",
    "    for i in range(3):\n",
    "        Recalls[i] = matrix[i][i]/sum(matrix[i])\n",
    "    Precisions = np.zeros(3)\n",
    "    pred_sum = matrix.sum(axis=0)\n",
    "    for i, ps in enumerate(pred_sum):\n",
    "        Precisions[i] = matrix[i][i]/ps\n",
    "    f1_score = 2*Recalls.mean()*Precisions.mean()/(Recalls.mean()+Precisions.mean())\n",
    "    return {\n",
    "        \"recalls\":Recalls,\n",
    "        \"precisions\":Precisions,\n",
    "        \"f1\":f1_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.to_csv('../data/clean/mount_data.csv', index=False)\n",
    "# df1.to_excel('../data/clean/mount_data.xlsx', index=False)\n",
    "# df1 = pd.read_excel('../data/clean/mount_data.xlsx')\n",
    "# df1 = df1.dropna()\n",
    "# df1[\"type\"]=df1.target\n",
    "# df1 = make_bad_feature(df1, badwordlist=badwordlist, positivelist=positivelist, hinikulist=hinikulist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1[df1.target==0].shape[0], df1[df1.target==1].shape[0],df1[df1.target==2].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "predのキー\n",
    "dict_keys(['pred_train', 'pred_test', 'x_train', 'new_x_train', 'y_train',\\\n",
    "'new_x_test', 'x_test', 'y_test', 'train_content', 'test_content'])\n",
    "'''\n",
    "\n",
    "def print_miss_pred(pred, test=True, true_y=np.nan, pred_y=np.nan,df=np.nan):\n",
    "    if test:\n",
    "        true_y = pred[\"y_test\"]\n",
    "        pred_y = pred[\"pred_test\"]\n",
    "        df     = pred[\"test_content\"]\n",
    "    else:\n",
    "        true_y = pred[\"y_train\"]\n",
    "        pred_y = pred[\"pred_train\"]\n",
    "        df     = pred[\"train_content\"]\n",
    "\n",
    "\n",
    "    idx_arr = []\n",
    "    pred_judge=[]\n",
    "    true_judge=[]\n",
    "    for i in range(len(pred_y)):\n",
    "        if pred_y[i]!=true_y.values[i]:\n",
    "#             print(pred[i], true_y.values[i])\n",
    "            idx_arr.append(i)\n",
    "            pred_judge.append(pred_y[i])\n",
    "            true_judge.append(true_y.values[i])\n",
    "\n",
    "    def print_str_label(num):\n",
    "        if num==0:return \"ニュートラル\"\n",
    "        if num==1:return \"悪口\"\n",
    "        if num==2:return \"皮肉\"\n",
    "        return np.nan\n",
    "    \n",
    "    col=[\"content\",\"true_label_id\",\"true_label\",\"pred_label_id\",\"pred_label\"]\n",
    "    miss_data = pd.DataFrame(columns=col)\n",
    "    for i,idx in enumerate(idx_arr):\n",
    "        tmpdf = pd.DataFrame(np.array([df.iloc[idx].content, true_judge[i],\\\n",
    "                                          print_str_label(true_judge[i]), pred_judge[i],\\\n",
    "                                        print_str_label(pred_judge[i])]).reshape(1,-1),columns=col)\n",
    "        miss_data = pd.concat([miss_data, tmpdf])\n",
    "        \n",
    "#             display(df.iloc[idx].content)\n",
    "#             print('true label  *',true_judge[i] , (print_str_label(true_judge[i])))\n",
    "#             print('pred label  *',pred_judge[i], (print_str_label(pred_judge[i])))\n",
    "#             print(\"------------------------------------------------------------------------------------\")\n",
    "        \n",
    "    print(miss_data.shape)\n",
    "    return miss_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/clean/mount_data.csv').dropna()\n",
    "df[\"comment_id\"] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n他のベクトル変換の例\\n\\nx_train,x_test, y_train, y_test = train_test_split(content, target, random_state=42)\\n\\n・バイナリ\\nvec = CountVectorizer(binary=True)\\ntrain_and_val(x_train, x_test, y_train, y_test, vec)\\n\\n・カウント\\nprint('count')\\nvec = CountVectorizer(binary=False)\\ntrain_and_val(x_train, x_test, y_train, y_test, vec)\\n\\n\\n・TfIdf\\nvec = TfidfVectorizer()\\nvectorize(x_train, x_test, y_train, y_test, vec)\\n\\n・bigram\\nvec = TfidfVectorizer(ngram_range=(1,3))\\ntrain_and_val(x_train, x_test, y_train, y_test, vec)\\n\""
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "他のベクトル変換の例\n",
    "\n",
    "x_train,x_test, y_train, y_test = train_test_split(content, target, random_state=42)\n",
    "\n",
    "・バイナリ\n",
    "vec = CountVectorizer(binary=True)\n",
    "train_and_val(x_train, x_test, y_train, y_test, vec)\n",
    "\n",
    "・カウント\n",
    "print('count')\n",
    "vec = CountVectorizer(binary=False)\n",
    "train_and_val(x_train, x_test, y_train, y_test, vec)\n",
    "\n",
    "\n",
    "・TfIdf\n",
    "vec = TfidfVectorizer()\n",
    "vectorize(x_train, x_test, y_train, y_test, vec)\n",
    "\n",
    "・bigram\n",
    "vec = TfidfVectorizer(ngram_range=(1,3))\n",
    "train_and_val(x_train, x_test, y_train, y_test, vec)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>mophologics_num</th>\n",
       "      <th>bad_per_mophologic</th>\n",
       "      <th>simple_bad_flg</th>\n",
       "      <th>target</th>\n",
       "      <th>hiniku_per_mophologic</th>\n",
       "      <th>simple_hiniku_flg</th>\n",
       "      <th>positive_per_mophologic</th>\n",
       "      <th>simple_positive_flg</th>\n",
       "      <th>comment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ガイジ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>くどい</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  content  mophologics_num  bad_per_mophologic  simple_bad_flg  target  \\\n",
       "0     ガイジ                1                   1               1       1   \n",
       "1     くどい                1                   1               1       1   \n",
       "\n",
       "   hiniku_per_mophologic  simple_hiniku_flg  positive_per_mophologic  \\\n",
       "0                      0                  0                        0   \n",
       "1                      0                  0                        0   \n",
       "\n",
       "   simple_positive_flg  comment_id  \n",
       "0                    0           0  \n",
       "1                    0           1  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nagataeiki/opt/anaconda3/envs/learning/lib/python3.8/site-packages/pandas/core/frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin\n",
      "[[592.   0.   0.]\n",
      " [  0. 741.   5.]\n",
      " [ 41.   0. 333.]]\n",
      "{'recalls': array([1.        , 0.99329759, 0.89037433]), 'Precisions': array([0.93522907, 1.        , 0.9852071 ]), 'f1': 0.9673125359877756}\n",
      "\n",
      "\n",
      "[[155.   0.   0.]\n",
      " [  0. 184.   2.]\n",
      " [  4.   0.  83.]]\n",
      "{'recalls': array([1.        , 0.98924731, 0.95402299]), 'Precisions': array([0.97484277, 1.        , 0.97647059]), 'f1': 0.98242878020966}\n"
     ]
    }
   ],
   "source": [
    "pred = train_and_predict(df)\n",
    "matrix=create_3x3_matrix(pred[\"y_train\"], pred[\"pred_train\"])\n",
    "print(matrix)\n",
    "print(calc_scores(matrix))\n",
    "print()\n",
    "print()\n",
    "matrix=create_3x3_matrix(pred[\"y_test\"], pred[\"pred_test\"])\n",
    "print(matrix)\n",
    "print(calc_scores(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>true_label_id</th>\n",
       "      <th>true_label</th>\n",
       "      <th>pred_label_id</th>\n",
       "      <th>pred_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>このばばぁ　頭おかしいな</td>\n",
       "      <td>1</td>\n",
       "      <td>悪口</td>\n",
       "      <td>2</td>\n",
       "      <td>皮肉</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>マジでナチス以下だな。内政すらうまくない</td>\n",
       "      <td>1</td>\n",
       "      <td>悪口</td>\n",
       "      <td>2</td>\n",
       "      <td>皮肉</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>保守はきれいな人多いな</td>\n",
       "      <td>2</td>\n",
       "      <td>皮肉</td>\n",
       "      <td>0</td>\n",
       "      <td>ニュートラル</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>今は紳士的</td>\n",
       "      <td>2</td>\n",
       "      <td>皮肉</td>\n",
       "      <td>0</td>\n",
       "      <td>ニュートラル</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>動物の習性って思って諦めるしかないな。</td>\n",
       "      <td>2</td>\n",
       "      <td>皮肉</td>\n",
       "      <td>0</td>\n",
       "      <td>ニュートラル</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>言葉だけは立派ですね</td>\n",
       "      <td>2</td>\n",
       "      <td>皮肉</td>\n",
       "      <td>0</td>\n",
       "      <td>ニュートラル</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                content true_label_id true_label pred_label_id pred_label\n",
       "0          このばばぁ　頭おかしいな             1         悪口             2         皮肉\n",
       "0  マジでナチス以下だな。内政すらうまくない             1         悪口             2         皮肉\n",
       "0           保守はきれいな人多いな             2         皮肉             0     ニュートラル\n",
       "0                 今は紳士的             2         皮肉             0     ニュートラル\n",
       "0   動物の習性って思って諦めるしかないな。             2         皮肉             0     ニュートラル\n",
       "0            言葉だけは立派ですね             2         皮肉             0     ニュートラル"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_miss_pred(pred, test=True, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
