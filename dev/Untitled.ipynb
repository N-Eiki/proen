{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "warnings.simplefilter('ignore')\n",
    "sys.path.append('/Users/nagataeiki/.pyenv/versions/3.7.4/lib/python3.7/site-packages')\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bad = pd.read_csv('../data/clean/cleaned_bad.csv')\n",
    "normal=pd.read_csv('../data/clean/cleaned_normal.csv')\n",
    "# hiniku_=pd.read_csv('../data/hiniku/hiniku_with_word.csv')\n",
    "hiniku = pd.read_csv(\"../data/clean/cleaned_hiniku.csv\")\n",
    "df = pd.read_csv('../data/clean/mount_all_data.csv')\n",
    "# df.drop('comment_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "badwordlist = pd.read_csv('../data/clean/mount_bad_list.csv')\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "tokenizer=Tokenizer()\n",
    "badwordlist_reading = []\n",
    "for word  in badwordlist.bad.values:\n",
    "    text=\"\"\n",
    "    for t in tokenizer.tokenize(word):\n",
    "        if t.reading==\"*\":\n",
    "            pass\n",
    "        else:\n",
    "            text+=t.reading\n",
    "    if len(text)>=1:\n",
    "        badwordlist_reading.append(text)\n",
    "# pd.DataFrame(badwordlist_reading).to_csv('../data/clean/badwordlist_reading.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(res1, res2, res3,threshold=0.5,display=True):\n",
    "    train_ensemble = pd.DataFrame(np.array([res1[\"pred_train_un\"],res2[\"pred_train_un\"],res2[\"pred_train_un\"]]).sum(axis=0)/3,columns=[\"pred\"])\n",
    "    test_ensemble = pd.DataFrame(np.array([res1[\"pred_test_un\"],res2[\"pred_test_un\"],res2[\"pred_test_un\"]]).sum(axis=0)/3,columns=[\"pred\"])\n",
    "    train_ensemble = train_ensemble.pred.apply(lambda x: 1 if x>threshold else 0)\n",
    "    test_ensemble = test_ensemble.pred.apply(lambda x: 1 if x>threshold else 0)\n",
    "    train_score = f1_score(res1['y_train'], train_ensemble)\n",
    "    test_score = f1_score(res1['y_test'], test_ensemble)\n",
    "    \n",
    "    miss_pred_tr = print_2x2_miss_pred(true_y=res1[\"y_train_untreat\"], pred_y=train_ensemble, df=res1[\"x_train\"],label=\"train\")\n",
    "    miss_pred_te = print_2x2_miss_pred(true_y=res1[\"y_test_untreat\"], pred_y=test_ensemble, df=res1[\"x_test\"],label=\"test\")\n",
    "#     coll_pred_tr = print_2x2_collect_pred(true_y=res1[\"y_train_untreat\"], pred_y=train_ensemble, df=res1[\"x_train\"])\n",
    "#     coll_pred_te = print_2x2_collect_pred(true_y=res1[\"y_test_untreat\"], pred_y=test_ensemble, df=res1[\"x_test\"])\n",
    "    coll_pred_tr = print_2x2_collect_pred(true_y=res1[\"y_train\"], pred_y=train_ensemble, df=res1[\"x_train\"],label=\"train\")\n",
    "    coll_pred_te = print_2x2_collect_pred(true_y=res1[\"y_test\"], pred_y=test_ensemble, df=res1[\"x_test\"],label=\"test\")\n",
    "    \n",
    "    \n",
    "    miss_pred_tr.pred_idx = miss_tr.pred_idx.apply(lambda x: int(x))\n",
    "    miss_pred_te.pred_idx = miss_te.pred_idx.apply(lambda x: int(x))\n",
    "    coll_pred_tr.pred_idx = coll_tr.pred_idx.apply(lambda x: int(x))\n",
    "    coll_pred_te.pred_idx = coll_te.pred_idx.apply(lambda x: int(x))\n",
    "    \n",
    "    matrix_tr=np.array([coll_tr[coll_tr.pred_idx!=1].shape[0],\n",
    "               miss_tr[miss_tr.pred_idx==1].shape[0],\n",
    "               miss_tr[miss_tr.pred_idx!=1].shape[0], \n",
    "               coll_tr[coll_tr.pred_idx==1].shape[0]]).reshape(2,-1)\n",
    "    \n",
    "    matrix_te=np.array([coll_te[coll_te.pred_idx!=1].shape[0],\n",
    "           miss_te[miss_te.pred_idx==1].shape[0],\n",
    "           miss_te[miss_te.pred_idx!=1].shape[0], \n",
    "           coll_te[coll_te.pred_idx==1].shape[0]]).reshape(2,-1)\n",
    "    if display:\n",
    "        print(\"train:\")\n",
    "        print(train_score)\n",
    "        print(matrix_tr)\n",
    "        print('test:')\n",
    "        print(test_score)\n",
    "        print(matrix_te)\n",
    "    \n",
    "    return {\"train_score\":train_score,\n",
    "            \"test_score\":test_score,\n",
    "            \"pred_train\":train_ensemble,\n",
    "            \"pred_test\":test_ensemble,\n",
    "#             \"miss_train_df\":miss_pred_tr,\n",
    "#             \"miss_test_df\":miss_pred_te,\n",
    "#             \"collect_train_df\":coll_pred_tr,\n",
    "#             \"collect_test_df\":coll_pred_te,\n",
    "            \"matrix_tr\":matrix_tr,\n",
    "            \"matrix_te\":matrix_te,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def train_and_pred(df, threshold=0.5, debug=False, random_state=42,display=True):\n",
    "    df = df.dropna()\n",
    "    ids = df.id.values\n",
    "    X = df.drop([\"target\"],axis=1)#.drop('content', axis=1)\n",
    "    y=df[\"target\"]\n",
    "    x_train, x_test, y_train_untreat, y_test_untreat = train_test_split(X,y, test_size=0.2, random_state=random_state)    \n",
    "    \n",
    "    y_train = y_train_untreat.apply(lambda x: 1 if x==1 else 0)#悪口\n",
    "    y_test = y_test_untreat.apply(lambda x: 1 if x==1 else 0)\n",
    "\n",
    "    tr_id = x_train.id.values\n",
    "    x_train.drop('id', axis=1, inplace=True)\n",
    "    te_id = x_test.id.values\n",
    "    x_test.drop('id', axis=1, inplace=True)\n",
    "    \n",
    "    svm = SVR()\n",
    "    svm.fit(x_train.drop(['content'], axis=1), y_train)\n",
    "    pred_train_unadjust = svm.predict(x_train.drop(['content'], axis=1))\n",
    "    pred_test_unadjust = svm.predict(x_test.drop(['content'], axis=1))\n",
    "    pred_train = [1 if x>threshold else 0 for x in pred_train_unadjust]\n",
    "    pred_test = [1 if x>threshold else 0 for x in pred_test_unadjust]\n",
    "    \n",
    "    if display:\n",
    "        print(\"train\")\n",
    "        print(\"f1: \" ,f1_score(y_train, pred_train))\n",
    "        print(create_2x2_matrix(y_train, pred_train))\n",
    "        # print_2x2_miss_pred(y_train, pred_train,x_train)\n",
    "        print('---------------------------------')\n",
    "        print('test')\n",
    "\n",
    "        print(\"f1: \",f1_score(y_test, pred_test))\n",
    "        print(create_2x2_matrix(y_test, pred_test))\n",
    "        print('---------------------------------')\n",
    "        print('---------------------------------')\n",
    "    train_miss = print_2x2_miss_pred(true_y=y_train_untreat,pred_y=pred_train, label=\"train\",df=x_train)\n",
    "    test_miss =  print_2x2_miss_pred(true_y=y_test_untreat, pred_y=pred_test, label=\"test\",df=x_test)\n",
    "    train_coll = print_2x2_collect_pred(true_y=y_train_untreat,pred_y=pred_train, label=\"train\",df=x_train)\n",
    "    test_coll = print_2x2_collect_pred(true_y=y_test_untreat, pred_y=pred_test, label=\"test\",df=x_test)\n",
    "    df[\"id\"]= ids\n",
    "    return {\n",
    "        \"miss_train_df\":train_miss, \n",
    "        \"miss_test_df\":test_miss,\n",
    "        \"collect_train_df\":train_coll,\n",
    "        \"collect_test_df\":test_coll,\n",
    "        \"x_train\":x_train,\n",
    "        \"y_train\":y_train,\n",
    "        \"x_test\":x_test,\n",
    "        \"y_test\":y_test,\n",
    "        \"pred_train\":pred_train,\n",
    "        \"pred_test\":pred_test,\n",
    "        \"model\":svm,\n",
    "        \"pred_train_un\":pred_train_unadjust,\n",
    "        \"pred_test_un\":pred_test_unadjust,\n",
    "        \"df\":df,\n",
    "#         \"train_id\":tr_id,\n",
    "#         \"test_id\":te_id,\n",
    "        \"y_train_untreat\":y_train_untreat,\n",
    "        \"y_test_untreat\":y_test_untreat\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_2x2_matrix(true_y, pred_y):\n",
    "    matrix = np.zeros(4)\n",
    "\n",
    "    for t,p in zip(true_y, pred_y):\n",
    "        if t==0:\n",
    "            if p==0:matrix[0]+=1\n",
    "            if p==1:matrix[1]+=1\n",
    "        elif t==1:\n",
    "            if p==0:matrix[2]+=1\n",
    "            if p==1:matrix[3]+=1\n",
    "    return matrix.reshape(2,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_2x2_miss_pred(true_y, pred_y,df, label,test=True):\n",
    "    def print_str_label(num, phase=\"predict\"):\n",
    "        if phase==\"predict\":\n",
    "            if num==0:return \"その他\"\n",
    "            if num==1:return \"悪口\"\n",
    "            else:\n",
    "                return np.nan\n",
    "            \n",
    "        else:   \n",
    "            if num==0:return \"その他[普通]\"\n",
    "            if num==1:return \"悪口\"\n",
    "            if num==2:return \"その他[皮肉]\"\n",
    "            return np.nan\n",
    "\n",
    "    idx_arr = []\n",
    "    pred_judge=[]\n",
    "    true_judge=[]\n",
    "    col=[\"label\",\"content\",\"judge\", \"pred_idx\", \"pred_label\",\"true_idx\", \"true_label\"]\n",
    "    returndf = pd.DataFrame(columns=col)\n",
    "    for i in range(len(df)):\n",
    "        if pred_y[i]!=true_y.values[i] and abs(pred_y[i]-true_y.values[i])!=2:\n",
    "            tmpdf = pd.DataFrame(np.array([label,df.iloc[i].content,\"miss\", pred_y[i], print_str_label(pred_y[i],phase=\"predict\"),\\\n",
    "                                            true_y.values[i], print_str_label(true_y.values[i], phase=\"\")]).reshape(1,-1), \\\n",
    "                                              columns=col)\n",
    "            returndf = pd.concat([returndf, tmpdf])\n",
    "    return returndf\n",
    "\n",
    "\n",
    "def print_2x2_collect_pred(true_y, pred_y,df,label, test=True):\n",
    "    def print_str_label(num, phase):\n",
    "        \n",
    "        if phase==\"predict\":\n",
    "            if num==0:return \"その他\"\n",
    "            if num==1:return \"悪口\"\n",
    "            else:\n",
    "                return np.nan\n",
    "            \n",
    "        else:   \n",
    "            if num==0:return \"その他[普通]\"\n",
    "            if num==1:return \"悪口\"\n",
    "            if num==2:return \"その他[皮肉]\"\n",
    "            return np.nan\n",
    "        \n",
    "    idx_arr = []\n",
    "    pred_judge=[]\n",
    "    true_judge=[]\n",
    "    col=[\"label\",\"content\", \"judge\",\"pred_idx\", \"pred_label\",\"true_idx\", \"true_label\"]\n",
    "    returndf = pd.DataFrame(columns=col)\n",
    "    for i in range(len(df)):\n",
    "        if pred_y[i]==true_y.values[i]:\n",
    "            tmpdf = pd.DataFrame(np.array([label,df.iloc[i].content,\"collect\", pred_y[i], print_str_label(pred_y[i],phase=\"predict\"),\\\n",
    "                                            true_y.values[i], print_str_label(true_y.values[i], phase=\"\")]).reshape(1,-1), \\\n",
    "                                              columns=col)\n",
    "            returndf = pd.concat([returndf, tmpdf])\n",
    "    return returndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wakati_content(text):\n",
    "    wakati = []\n",
    "    for t in tokenizer.tokenize(text):\n",
    "        wakati.append(t.surface)\n",
    "    return wakati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "# # data = pd.read_csv('../data/clean/mount_bad_list.csv')\n",
    "# data = pd.read_csv(\"../data/clean/mount_all_data.csv\")\n",
    "# data = data[data.type==1]\n",
    "wakati_arr = []\n",
    "# for r in tqdm(data.iterrows()):\n",
    "#     wakati = create_wakati_content(r[1].content)\n",
    "#     wakati_arr.append(wakati)\n",
    "# model = Word2Vec(wakati_arr, sg=1, size=100, window=5, min_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('../data/some_comment_data.csv')\n",
    "\n",
    "# for r in tqdm(data.iterrows()):\n",
    "#     wakati = create_wakati_content(r[1].content)\n",
    "#     wakati_arr.append(wakati)\n",
    "# model = Word2Vec(wakati_arr, sg=1, size=100, window=5, min_count=1)\n",
    "# model.save(\"./word2vecModel/200000.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec.load(\"./word2vecModel/100000.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1929it [00:15, 122.84it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>mophologics_num</th>\n",
       "      <th>bad_count_in_mophologic</th>\n",
       "      <th>simple_bad_flg</th>\n",
       "      <th>target</th>\n",
       "      <th>order</th>\n",
       "      <th>mophologic_content</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>なにこの糞ゲー</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[なに, この, 糞, ゲー]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ちょっと蛇足気味だな・・・</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[ちょっと, 蛇足, 気味, だ, な, ・, ・, ・]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         content  mophologics_num  bad_count_in_mophologic  simple_bad_flg  \\\n",
       "0        なにこの糞ゲー              4.0                      1.0               1   \n",
       "1  ちょっと蛇足気味だな・・・              8.0                      1.0               1   \n",
       "\n",
       "   target  order             mophologic_content  id  \n",
       "0       1      0                [なに, この, 糞, ゲー]   0  \n",
       "1       1      0  [ちょっと, 蛇足, 気味, だ, な, ・, ・, ・]   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1929, 8)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "悪口ワードの含有\n",
    "皮肉ワードの含有\n",
    "ポジティブワードの含有\n",
    "\n",
    "[形態素解析した時の単語数],[単純に悪口単語が文章に含まれているのかのフラグ], [形態素ごとに現れる悪口数]\n",
    "[皮肉単語が含まれているかのフラグ],[形態素ごとに現れる皮肉数]\n",
    "[ポジティブな単語が含まれているかのフラグ], [形態素ごとに現れるポジティブ単語数]\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "# df = bad.copy()\n",
    "# df = pd.concat([hiniku_, normal])\n",
    "# df = pd.concat([bad, df])\n",
    "import sys\n",
    "import numpy as np\n",
    "from janome.tokenizer import Tokenizer\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "\n",
    "df = pd.read_csv('../data/clean/mount_all_data.csv')\n",
    "df.drop('comment_id', axis=1, inplace=True)\n",
    "tokenizer = Tokenizer()\n",
    "#悪口が含まれている数のカウント, 単に含まれているのかのフラグを返す\n",
    "def get_word_count(text, wordlist):\n",
    "    textlist = []\n",
    "    count=0\n",
    "    flg=0\n",
    "    for t in tokenizer.tokenize(text):\n",
    "        if t.surface in wordlist:\n",
    "            count+=1\n",
    "    for w in wordlist:\n",
    "        if w in text:\n",
    "            flg=1\n",
    "            return count, flg\n",
    "    \n",
    "    return count,flg\n",
    "\n",
    "\n",
    "def get_order_label(text):\n",
    "    for t in tokenizer.tokenize(text):\n",
    "        if t.infl_form[:2]==\"命令\":\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "def cos_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "\n",
    "'''\n",
    "###ここを実行することでword2vecのモデル作成\n",
    "from gensim.models import Word2Vec\n",
    "data = pd.read_csv('../data/some_comment_data.csv')\n",
    "newdata=pd.concat([pd.DataFrame(data.content), pd.DataFrame(df.content)])\n",
    "wakati_arr = []\n",
    "for r in tqdm(newdata.iterrows()):\n",
    "    wakati = create_wakati_content(r[1].content)\n",
    "    wakati_arr.append(wakadti)\n",
    "model = Word2Vec(wakati_arr, sg=1, size=100, window=5, min_count=1)\n",
    "'''\n",
    "\n",
    "def calc_cosine_similary(text,model,debug=False):\n",
    "    text_list = []\n",
    "    scores = {}\n",
    "\n",
    "    for t in tokenizer.tokenize(text):\n",
    "        text_list.append(t.surface)\n",
    "    for word in text_list:\n",
    "        try:\n",
    "            vector1 = model.wv[word]\n",
    "            scores[word] = []\n",
    "            for bad in bad_list:\n",
    "                try:\n",
    "                    vector2 = model.wv[bad]\n",
    "                    score = cos_similarity(vector1,vector2)\n",
    "                    scores[word].append(score)\n",
    "                except :\n",
    "                    pass\n",
    "        except:\n",
    "            pass\n",
    "    all_scores = []\n",
    "    for scores in scores.values():\n",
    "        all_scores +=scores\n",
    "    all_scores= np.array(all_scores)\n",
    "    typicalV = np.median(all_scores, axis=0)\n",
    "\n",
    "    if debug:\n",
    "        return scores\n",
    "    return typicalV\n",
    "\n",
    "\n",
    "def mophologicize(text):\n",
    "    words = []\n",
    "    for t in tokenizer.tokenize(text):\n",
    "        words.append(t.surface)    \n",
    "    return words\n",
    "\n",
    "\n",
    "#dfと悪口辞書を入れて新しい特徴量を含んだdfを返す\n",
    "def make_features(df, badwordlist, positivelist=np.nan, hinikulist=np.nan):\n",
    "#     col=[\"content\",\"mophologics_num\", \"bad_per_mophologic\", \"simple_bad_flg\",\"target\", \"hiniku_per_mophologic\",\\\n",
    "#          \"simple_hiniku_flg\", \"positive_per_mophologic\", \"simple_positive_flg\"]\n",
    "#     import gensim\n",
    "#     PATH=\"./gensimmodel/word2vec.gensim.model\"\n",
    "#     model = gensim.models.Word2Vec.load(PATH)\n",
    "    col=[\"content\",\"mophologics_num\", \"bad_count_in_mophologic\", \"simple_bad_flg\",\"target\",\"order\",\"mophologic_content\"]\n",
    "\n",
    "    basedf = pd.DataFrame(columns=col)\n",
    "    tokenizer = Tokenizer()\n",
    "    for r in tqdm(df.iterrows()):\n",
    "        text = str(r[1].content)\n",
    "        target = r[1].type\n",
    "        num = len(tokenizer.tokenize(text))\n",
    "        badcount,badflg = get_word_count(text, badwordlist)\n",
    "        orderlabel = get_order_label(text)\n",
    "        mophologic = mophologicize(text)\n",
    "#         hinikucount, hinikuflg = get_word_count(text, hinikulist)\n",
    "#         positivecount, positiveflg = get_word_count(text, positivelist)\n",
    "#         newdf = pd.DataFrame(np.array([text, num, badcount,badflg,target,\\\n",
    "#                                        hinikucount, hinikuflg, positivecount,\\\n",
    "#                                        positiveflg]).reshape(1,-1),columns=col)\n",
    "        newdf = pd.DataFrame(np.array([text, num, badcount,badflg,target, orderlabel,mophologic]).reshape(1,-1),columns=col)\n",
    "        basedf = pd.concat([basedf, newdf])\n",
    "\n",
    "    basedf[\"target\"] = basedf.apply(lambda x: int(x[\"target\"]), axis=1)\n",
    "#     basedf[\"comment_id\"] = basedf.index\n",
    "    basedf[\"bad_count_in_mophologic\"] = basedf.apply(lambda x: float(x[\"bad_count_in_mophologic\"]), axis=1)\n",
    "    basedf[\"mophologics_num\"] = basedf.apply(lambda x: float(x[\"mophologics_num\"]), axis=1)\n",
    "    basedf[\"order\"] = basedf.order.apply(lambda x: int(x))\n",
    "#     basedf[\"cosine_similar\"] = basedf.cosine_similar.apply(lambda x: float(x))\n",
    "    \n",
    "    return basedf\n",
    "df =make_features(df, list(badwordlist.bad.values))\n",
    "df = df.fillna(0.0)\n",
    "# df = df[~df.duplicated(subset=\"content\")]\n",
    "df = df.reset_index().drop('index', axis=1)\n",
    "df[\"id\"] = df.index\n",
    "display(df.head(2))\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bad_word_list():\n",
    "    b_l=[]\n",
    "    #wor2vecの辞書にない単語の除外\n",
    "    for word in badwordlist.bad.values:\n",
    "        try:\n",
    "            a = model.wv[word]\n",
    "            b_l.append(word)\n",
    "        except:\n",
    "            pass\n",
    "    return b_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col=[]\n",
    "for i in range(100):\n",
    "    col.append(\"f_\"+str(i))\n",
    "def create_mean_vector_data(df):\n",
    "\n",
    "    sandbox=pd.DataFrame(columns=col)\n",
    "    for r in tqdm(df.iterrows()):\n",
    "        text = r[1].mophologic_content\n",
    "        vec_list=[]\n",
    "        for t in text:\n",
    "                try:\n",
    "                    vec = model.wv[t]\n",
    "                    vec_list.append(vec)\n",
    "                except:\n",
    "                    vec_list.append(np.zeros(100))\n",
    "        vectors = pd.DataFrame(np.array(vec_list), columns=col)\n",
    "        tmp = pd.DataFrame(pd.DataFrame(vectors, columns=col).mean(axis=0)).T\n",
    "        sandbox = pd.concat([sandbox, tmp])\n",
    "        \n",
    "\n",
    "    sandbox.insert(0, \"target\",df.target.values)\n",
    "    sandbox.insert(1,\"content\",df.content.values)\n",
    "    sandbox[\"id\"]= df.id.values\n",
    "    return sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mean_cosine_sim_data(df):\n",
    "    b_l=create_bad_word_list()\n",
    "    base = pd.DataFrame(columns=np.array(b_l))\n",
    "    \n",
    "    for r in tqdm(df.iterrows()):\n",
    "        text = r[1].mophologic_content\n",
    "        ave_list=[]\n",
    "\n",
    "        for word in b_l:\n",
    "            try:\n",
    "                v1 = model.wv[word]\n",
    "                cos_list = []\n",
    "                for t in text:\n",
    "                        v2=model.wv[t]\n",
    "                        cos_list.append(cos_similarity(v1,v2))\n",
    "                        if word not in b_l:\n",
    "                            b_l.append(word)\n",
    "            except:\n",
    "                pass\n",
    "            ave_list.append(np.array(cos_list).mean())\n",
    "        tmp=pd.DataFrame(np.array(ave_list).reshape(1,-1), columns=b_l)\n",
    "        base=pd.concat([base, tmp])\n",
    "        \n",
    "    base[\"target\"] =df.target.values\n",
    "    base[\"content\"] = df.content.values\n",
    "    base = base.loc[:,base.columns[::-1]]\n",
    "    base[\"id\"] = df.id.values\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_the_highest_cosine_sim_data(df):\n",
    "    b_l = create_bad_word_list()\n",
    "    base = pd.DataFrame(columns=np.array(b_l))\n",
    "    \n",
    "    for r in tqdm(df.iterrows()):\n",
    "        text = r[1].mophologic_content\n",
    "        highest_list=[]\n",
    "\n",
    "        for word in b_l:\n",
    "            try:\n",
    "                v1 = model.wv[word]\n",
    "                cos_list = []\n",
    "                for t in text:\n",
    "                        v2=model.wv[t]\n",
    "                        cos_list.append(cos_similarity(v1,v2))\n",
    "                        if word not in b_l:\n",
    "                            b_l.append(word)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                highest_list.append(np.array(cos_list).max())\n",
    "            except:\n",
    "                highest_list.append(np.nan)\n",
    "        tmp=pd.DataFrame(np.array(highest_list).reshape(1,-1), columns=b_l)\n",
    "        base=pd.concat([base, tmp])\n",
    "        \n",
    "    base[\"target\"] =df.target.values\n",
    "    base[\"content\"] = df.content.values\n",
    "    base = base.loc[:,base.columns[::-1]]\n",
    "    base[\"id\"] = df.id.values\n",
    "    return base\n",
    "\n",
    "\n",
    "# high_sim_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1929it [00:06, 303.51it/s]\n"
     ]
    }
   ],
   "source": [
    "df1 = create_mean_vector_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "f1:  0.7585743106926699\n",
      "[[620. 175.]\n",
      " [184. 564.]]\n",
      "---------------------------------\n",
      "test\n",
      "f1:  0.6704225352112677\n",
      "[[150.  52.]\n",
      " [ 65. 119.]]\n",
      "---------------------------------\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "res1 = train_and_pred(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1929it [00:50, 37.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "f1:  0.636429085673146\n",
      "[[545. 209.]\n",
      " [296. 442.]]\n",
      "---------------------------------\n",
      "test\n",
      "f1:  0.6382978723404256\n",
      "[[118.  62.]\n",
      " [ 74. 120.]]\n",
      "---------------------------------\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "df2 = create_mean_cosine_sim_data(df)\n",
    "res2 = train_and_pred(df2,threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1929it [00:54, 35.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "f1:  0.6666666666666666\n",
      "[[566. 188.]\n",
      " [275. 463.]]\n",
      "---------------------------------\n",
      "test\n",
      "f1:  0.6892655367231638\n",
      "[[142.  38.]\n",
      " [ 72. 122.]]\n",
      "---------------------------------\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "df3 = create_the_highest_cosine_sim_data(df)\n",
    "res3 = train_and_pred(df3,threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1929, 103), (1929, 155), (1929, 155))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape, df2.shape, df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1929, 103), (1866, 155), (1866, 155))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1[\"df\"].shape,res2[\"df\"].shape,res3[\"df\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_id = list(res2[\"df\"].id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1929/1929 [00:05<00:00, 370.70it/s]\n"
     ]
    }
   ],
   "source": [
    "newdf = pd.DataFrame(columns=df.columns)\n",
    "for i in tqdm(range(len(df))):\n",
    "    if i in valid_id:\n",
    "        tmp = pd.DataFrame(df.iloc[i]).T\n",
    "        newdf = pd.concat([newdf, tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for r in newdf.iterrows():\n",
    "#     if \"w\" in r[1].content:\n",
    "#         r[1].content = r[1].content.replace(\"w\", \"\")+\"w\"\n",
    "#     if \" \" in r[1].content:\n",
    "#         r[1].content = r[1].content.replace(' ', \"\")\n",
    "#     if \"　\" in r[1].content:\n",
    "#         r[1].content = r[1].content.replace('　', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1866it [00:07, 242.30it/s]\n",
      "1866it [00:43, 43.11it/s]\n",
      "1866it [00:54, 34.11it/s]\n"
     ]
    }
   ],
   "source": [
    "df1=create_mean_vector_data(newdf)\n",
    "df2=create_the_highest_cosine_sim_data(newdf)\n",
    "df3=create_mean_cosine_sim_data(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = train_and_pred(df1,)\n",
    "res2 = train_and_pred(df2,)\n",
    "res3 = train_and_pred(df3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.7402689313517339\n",
      "[[602 152]\n",
      " [215 523]]\n",
      "test:\n",
      "0.7645429362880886\n",
      "[[151  29]\n",
      " [ 56 138]]\n"
     ]
    }
   ],
   "source": [
    "res=ensemble(res1,res2,res3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1=create_mean_vector_data(newdf)\n",
    "# df2=create_the_highest_cosine_sim_data(newdf)\n",
    "# df3=create_mean_cosine_sim_data(newdf)\n",
    "# res1 = train_and_pred(df1, display=False)\n",
    "# res2 = train_and_pred(df2, display=False)\n",
    "# res3 = train_and_pred(df3, display=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def change_seed(df1,df2,df3,show=False, iterations=5):\n",
    "    trains=[]\n",
    "    tests =[]\n",
    "\n",
    "    for i in tqdm(range(iterations)):\n",
    "        res1 = train_and_pred(df1,display=show)\n",
    "        res2 = train_and_pred(df2,display=show)\n",
    "        res3 = train_and_pred(df3,display=show)\n",
    "        res=ensemble(res1,res2,res3,display=show)\n",
    "        trains.append(res[\"train_score\"])\n",
    "        tests.append(res[\"test_score\"])\n",
    "\n",
    "    trains = np.array(trains)\n",
    "    tests = np.array(tests)\n",
    "    if show:\n",
    "        print(trains.min(), trains.max(), trains.mean(),trains.var(ddof=-1))\n",
    "        print(tests.min(), tests.max(), tests.mean(),tests.var(ddof=-1))\n",
    "    return trains, tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:59<00:00, 11.88s/it]\n"
     ]
    }
   ],
   "source": [
    "tr, te = change_seed(df1, df2, df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7402689313517339 0.7402689313517339 0.7402689313517339 0.0\n",
      "0.7645429362880886 0.7645429362880886 0.7645429362880886 0.0\n"
     ]
    }
   ],
   "source": [
    "print(tr.min(), tr.max(), tr.mean(),tr.var(ddof=-1))\n",
    "print(te.min(), te.max(), te.mean(),te.var(ddof=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_tr=res[\"miss_train_df\"]\n",
    "miss_te=res[\"miss_test_df\"]\n",
    "coll_tr=res[\"collect_train_df\"]\n",
    "coll_te=res[\"collect_test_df\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_tr.to_csv('./predicted_data/miss_pred_train.csv', index=False)\n",
    "miss_te.to_csv('./predicted_data/miss_pred_test.csv', index=False)\n",
    "coll_tr.to_csv('./predicted_data/collect_pred_train.csv', index=False)\n",
    "coll_te.to_csv(\"./predicted_data/collect_pred_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[602 152]\n",
      " [215 523]]\n",
      "[[151  29]\n",
      " [ 56 138]]\n"
     ]
    }
   ],
   "source": [
    "print(res[\"matrix_tr\"])\n",
    "print(res[\"matrix_te\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #悪口と誤判定してしまった\n",
    "# res[\"miss_train_df\"].true_idx.value_counts()#普通 : 皮肉 = 83 ; 59\n",
    "# tmp = res[\"miss_train_df\"][res[\"miss_train_df\"].pred_idx==\"1\"]#\n",
    "# print(tmp[tmp.true_idx==\"2\"].shape)#悪口と判定された皮肉\n",
    "# tmp[tmp.true_idx==\"2\"]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train 正しく悪口\n",
    "普通に悪口のやつ\n",
    "523/675\n",
    "\n",
    "--------------------------------\n",
    "train 正しくその他\n",
    "602/817\n",
    "\n",
    "--------------------------------\n",
    "train その他を誤って悪口\n",
    "その他[普通]    83/695\n",
    "その他[皮肉]    59/59\n",
    "\n",
    "--------------------------------\n",
    "train 悪口を誤ってその他\n",
    "209/738\n",
    "\n",
    "〇〇だけどxx(逆説などに弱い？？)\n",
    "直接的だが似たような音の言葉で代替している単語はあまり識別できていないように感じる\n",
    "例：　クズ-9ず, 死ね-氏ね\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "testデータについて\n",
    "\n",
    "ミスデータ\n",
    "1    56\n",
    "0    22\n",
    "2     7\n",
    "--------\n",
    "正解データ\n",
    "0    151\n",
    "1    138\n",
    "--------\n",
    "\n",
    "test 正しく悪口\n",
    "普通に悪口のやつ\n",
    "138/167\n",
    "\n",
    "--------------------------------\n",
    "test 正しくその他\n",
    "151/207\n",
    "\n",
    "--------------------------------\n",
    "test その他を誤って悪口\n",
    "29/207\n",
    "\n",
    "22(その他の割合\n",
    "\n",
    "?, !, ..., www, ぁぁぁ,〜 などの特殊な形の文末を持つ文章が多い？\n",
    "\n",
    "--------------------------------\n",
    "test 悪口を誤ってその他\n",
    "56/207\n",
    "悪口辞書の文字と少し形の違う文字\n",
    "クズ-kz（全角）\n",
    "遅い-おっそ\n",
    "うるさい-うっさ\n",
    "\n",
    "１単語や２単語合わせただけの短い文章\n",
    "exp)おっそ, 何これ？, 灰かよ, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = res[\"miss_train_df\"]\n",
    "b = res[\"miss_test_df\"]\n",
    "c = res[\"collect_train_df\"]\n",
    "d = res[\"collect_test_df\"]\n",
    "\n",
    "# train_df = pd.concat([a,c])\n",
    "# test_df = pd.concat([b,d])\n",
    "\n",
    "# predict_df = pd.concat([a,b,c,d])\n",
    "# train_df.to_csv('./predicted_data/train.csv', index=False)\n",
    "# test_df.to_csv('./predicted_data/test.csv',index=False)\n",
    "# predict_df.to_csv(\"./predicted_data/merged_train_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testdf = base.copy()\n",
    "# testdf = testdf.dropna()\n",
    "# # testdf.target = testdf.target.apply(lambda x: 0 if x==0 else 1)#x==0(ニュートラル)の時0, その他は1\n",
    "# testdf.target = testdf.target.apply(lambda x: 0 if x==1 else 1)#x==1(悪口)の時0, その他は1 [0:悪口, 1:その他]\n",
    "# # testdf.target = testdf.target.apply(lambda x: 0 if x==2 else 1)#x==2(皮肉)の時0, その他は1\n",
    "# testdf.target.unique()\n",
    "# testdf.target.unique()\n",
    "# X = testdf.drop(\"target\",axis=1)#.drop('content', axis=1)\n",
    "# y=testdf.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[602., 152.],\n",
       "       [215., 523.]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"matrix_tr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1866"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape[0]+ b.shape[0]+ c.shape[0]+d.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1対その他での学習\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "\n",
    "def train_and_predict_one_vs_rest(df):\n",
    "    \n",
    "    X = df.drop([\"target\",\"id\"],axis=1)\n",
    "    y = df.target\n",
    "    \n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "#     return x_train, y_train\n",
    "\n",
    "    train_content = pd.DataFrame(x_train.content.values, columns=[\"content\"])\n",
    "    test_content  = pd.DataFrame(x_test.content.values, columns=[\"content\"])\n",
    "#     x_train.drop(,axis=1,inplace=True)\n",
    "#     x_test.drop([\"content\"],axis=1,inplace=True)\n",
    "    svm = SVC()\n",
    "    ovr = OneVsRestClassifier(svm)\n",
    "    ovr.fit(x_train.drop('content',axis=1), list(y_train.values))\n",
    "    \n",
    "    tr_pre = ovr.predict(x_train.drop('content',axis=1))\n",
    "    te_pre = ovr.predict(x_test.drop('content',axis=1))\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return {\n",
    "#         \"pred_train_with_vec\":  vec_model.predict(new_x_train),\n",
    "#         \"pred_test_with_vec\": vec_model.predict(new_x_test),\n",
    "        \"pred_train\":ovr.predict(x_train.drop('content',axis=1)),\n",
    "        \"pred_test\":ovr.predict(x_test.drop('content',axis=1)),\n",
    "        \"x_train\":x_train,\n",
    "#         \"new_x_train\":new_x_train,\n",
    "        \"y_train\":y_train,\n",
    "#         \"new_x_test\":new_x_test,\n",
    "        \"x_test\":x_test,\n",
    "        \"y_test\":y_test,\n",
    "        \"train_content\":train_content,\n",
    "        \"test_content\":test_content,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "'''\n",
    "mxm,ここでは3x3のマトリックスを作成する\n",
    "そこからf1値を計算する（同ディレクトリの画像参照）\n",
    "'''\n",
    "\n",
    "def create_3x3_matrix(true_y, pred_y):\n",
    "    matrix = np.zeros(9)\n",
    "\n",
    "    for t,p in zip(true_y, pred_y):\n",
    "        t = int(t)\n",
    "        p = int(p)\n",
    "        if t==0:\n",
    "            if p==0:matrix[0]+=1\n",
    "            if p==1:matrix[1]+=1\n",
    "            if p==2:matrix[2]+=1\n",
    "        elif t==1:\n",
    "            if p==0:matrix[3]+=1\n",
    "            if p==1:matrix[4]+=1\n",
    "            if p==2:matrix[5]+=1\n",
    "        elif t==2:\n",
    "            if p==0:matrix[6]+=1\n",
    "            if p==1:matrix[7]+=1\n",
    "            if p==2:matrix[8]+=1\n",
    "\n",
    "    return matrix.reshape(3,3)\n",
    "# matrix=create_3x3_matrix(y_train, pred_train)\n",
    "# matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# matrix\n",
    "\n",
    "'''\n",
    "matrix = np.array([\n",
    "    [240,20, 40],\n",
    "    [5,180, 15],\n",
    "    [25, 5, 70]\n",
    "])\n",
    "動作例\n",
    "acc: 0.8000000000000002\n",
    "recall 0.7756458897922313\n",
    "f1: 0.7876347291657112\n",
    "'''\n",
    "def calc_3x3_matrix_f_score(matrix):\n",
    "\n",
    "    accs = []\n",
    "    recalls=[]\n",
    "    tate=matrix.sum(axis=0)#たて\n",
    "    yoko=matrix.sum(axis=1)#横\n",
    "    for i in range(3):\n",
    "        accs.append(matrix[i][i]/yoko[i])\n",
    "        recalls.append(matrix[i][i]/tate[i])\n",
    "    acc = np.mean(accs)\n",
    "    recall = np.mean(recalls)\n",
    "\n",
    "    f1 = 2*acc*recall/(acc+recall)\n",
    "    return {\n",
    "        \"acc\":acc,\n",
    "        \"recall\":recall,\n",
    "        \"f1\":f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1[df1.target==0].shape[0], df1[df1.target==1].shape[0],df1[df1.target==2].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "predのキー\n",
    "dict_keys(['pred_train', 'pred_test', 'x_train', 'new_x_train', 'y_train',\\\n",
    "'new_x_test', 'x_test', 'y_test', 'train_content', 'test_content'])\n",
    "'''\n",
    "\n",
    "def print_3x3miss_pred(pred, test=True, true_y=np.nan, pred_y=np.nan,df=np.nan):\n",
    "    if test:\n",
    "        true_y = pred[\"y_test\"]\n",
    "        pred_y = pred[\"pred_test\"]\n",
    "        df     = pred[\"test_content\"]\n",
    "    else:\n",
    "        true_y = pred[\"y_train\"]\n",
    "        pred_y = pred[\"pred_train\"]\n",
    "        df     = pred[\"train_content\"]\n",
    "\n",
    "\n",
    "    idx_arr = []\n",
    "    pred_judge=[]\n",
    "    true_judge=[]\n",
    "    for i in range(len(pred_y)):\n",
    "        if pred_y[i]!=true_y.values[i]:\n",
    "#             print(pred[i], true_y.values[i])\n",
    "            idx_arr.append(i)\n",
    "            pred_judge.append(pred_y[i])\n",
    "            true_judge.append(true_y.values[i])\n",
    "\n",
    "    def print_str_label(num):\n",
    "        if num==0:return \"ニュートラル\"\n",
    "        if num==1:return \"悪口\"\n",
    "        if num==2:return \"皮肉\"\n",
    "        return np.nan\n",
    "    \n",
    "    col=[\"content\",\"true_label_id\",\"true_label\",\"pred_label_id\",\"pred_label\"]\n",
    "    miss_data = pd.DataFrame(columns=col)\n",
    "    for i,idx in enumerate(idx_arr):\n",
    "        tmpdf = pd.DataFrame(np.array([df.iloc[idx].content, true_judge[i],\\\n",
    "                                          print_str_label(true_judge[i]), pred_judge[i],\\\n",
    "                                        print_str_label(pred_judge[i])]).reshape(1,-1),columns=col)\n",
    "        miss_data = pd.concat([miss_data, tmpdf])\n",
    "        \n",
    "#             display(df.iloc[idx].content)\n",
    "#             print('true label  *',true_judge[i] , (print_str_label(true_judge[i])))\n",
    "#             print('pred label  *',pred_judge[i], (print_str_label(pred_judge[i])))\n",
    "#             print(\"------------------------------------------------------------------------------------\")\n",
    "        \n",
    "    print(miss_data.shape)\n",
    "    return miss_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 create_mean_vector_data\n",
    "#df2 create_mean_cosine_sim_data\n",
    "#df3 createcreate_the_highest_cosine_sim_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'acc': 0.4988334641742502, 'recall': 0.7800663055590945, 'f1': 0.6085280280702309}\n",
      "[[309. 244.   0.]\n",
      " [ 79. 659.   0.]\n",
      " [ 46. 146.   9.]]\n",
      "test: {'acc': 0.4705326460481099, 'recall': 0.5290123456790123, 'f1': 0.4980617798391572}\n",
      "[[ 70.  69.   1.]\n",
      " [ 20. 172.   2.]\n",
      " [ 10.  29.   1.]]\n"
     ]
    }
   ],
   "source": [
    "# OneVsRest= train_and_predict_one_vs_rest(df1)\n",
    "# matrix_tr=create_3x3_matrix(true_y=OneVsRest[\"y_train\"], pred_y=OneVsRest[\"pred_train\"])\n",
    "# matrix_te=create_3x3_matrix(true_y=OneVsRest[\"y_test\"], pred_y=OneVsRest[\"pred_test\"])\n",
    "# print(\"train:\",calc_3x3_matrix_f_score(matrix_tr))\n",
    "# print(matrix_tr)\n",
    "# print(\"test:\",calc_3x3_matrix_f_score(matrix_te))\n",
    "# print(matrix_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'acc': 0.44383922139402227, 'recall': nan, 'f1': nan}\n",
      "[[271. 282.   0.]\n",
      " [117. 621.   0.]\n",
      " [ 61. 140.   0.]]\n",
      "test: {'acc': 0.41605301914580267, 'recall': nan, 'f1': nan}\n",
      "[[ 60.  80.   0.]\n",
      " [ 35. 159.   0.]\n",
      " [ 13.  27.   0.]]\n"
     ]
    }
   ],
   "source": [
    "# OneVsRest= train_and_predict_one_vs_rest(df2)\n",
    "# matrix_tr=create_3x3_matrix(true_y=OneVsRest[\"y_train\"], pred_y=OneVsRest[\"pred_train\"])\n",
    "# matrix_te=create_3x3_matrix(true_y=OneVsRest[\"y_test\"], pred_y=OneVsRest[\"pred_test\"])\n",
    "# print(\"train:\",calc_3x3_matrix_f_score(matrix_tr))\n",
    "# print(matrix_tr)\n",
    "# print(\"test:\",calc_3x3_matrix_f_score(matrix_te))\n",
    "# print(matrix_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'acc': 0.4185213394062634, 'recall': 0.5800970795763215, 'f1': 0.48623779036100034}\n",
      "[[214. 337.   2.]\n",
      " [108. 630.   0.]\n",
      " [ 50. 148.   3.]]\n",
      "test: {'acc': 0.3930289641629848, 'recall': nan, 'f1': nan}\n",
      "[[ 46.  94.   0.]\n",
      " [ 29. 165.   0.]\n",
      " [ 14.  26.   0.]]\n"
     ]
    }
   ],
   "source": [
    "# OneVsRest= train_and_predict_one_vs_rest(df3)\n",
    "# matrix_tr=create_3x3_matrix(true_y=OneVsRest[\"y_train\"], pred_y=OneVsRest[\"pred_train\"])\n",
    "# matrix_te=create_3x3_matrix(true_y=OneVsRest[\"y_test\"], pred_y=OneVsRest[\"pred_test\"])\n",
    "# print(\"train:\",calc_3x3_matrix_f_score(matrix_tr))\n",
    "# print(matrix_tr)\n",
    "# print(\"test:\",calc_3x3_matrix_f_score(matrix_te))\n",
    "# print(matrix_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
