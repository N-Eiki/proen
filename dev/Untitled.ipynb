{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "warnings.simplefilter('ignore')\n",
    "sys.path.append('/Users/nagataeiki/.pyenv/versions/3.7.4/lib/python3.7/site-packages')\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bad = pd.read_csv('../data/clean/cleaned_bad.csv')\n",
    "normal=pd.read_csv('../data/clean/cleaned_normal.csv')\n",
    "# hiniku_=pd.read_csv('../data/hiniku/hiniku_with_word.csv')\n",
    "hiniku = pd.read_csv(\"../data/clean/cleaned_hiniku.csv\")\n",
    "df = pd.read_csv('../data/clean/mount_all_data.csv')\n",
    "# df.drop('comment_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "badwordlist = pd.read_csv('../data/clean/mount_bad_list.csv')\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "tokenizer=Tokenizer()\n",
    "badwordlist_reading = []\n",
    "for word  in badwordlist.bad.values:\n",
    "    text=\"\"\n",
    "    for t in tokenizer.tokenize(word):\n",
    "        if t.reading==\"*\":\n",
    "            pass\n",
    "        else:\n",
    "            text+=t.reading\n",
    "    if len(text)>=1:\n",
    "        badwordlist_reading.append(text)\n",
    "# pd.DataFrame(badwordlist_reading).to_csv('../data/clean/badwordlist_reading.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# badwordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def train_and_pred(df, threshold=0.5):\n",
    "    df = df.dropna()\n",
    "    # testdf.target = testdf.target.apply(lambda x: 0 if x==0 else 1)#x==0(ニュートラル)の時0, その他は1\n",
    "    if len(df.target.unique())>2:\n",
    "        df.target = df.target.apply(lambda x: 1 if x==1 else 0)#x==1(悪口)の時1, その他は0 [0:悪口, 1:その他]\n",
    "    # testdf.target = testdf.target.apply(lambda x: 0 if x==2 else 1)#x==2(皮肉)の時0, その他は1\n",
    "    X = df.drop([\"target\"],axis=1)#.drop('content', axis=1)\n",
    "    y=df[\"target\"]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)    \n",
    "\n",
    "    svm = SVR()\n",
    "    svm.fit(x_train.drop(['content'], axis=1), y_train)\n",
    "    pred_train_unadjust = svm.predict(x_train.drop(['content'], axis=1))\n",
    "    pred_test_unadjust = svm.predict(x_test.drop(['content'], axis=1))\n",
    "\n",
    "    print(\"train\")\n",
    "\n",
    "    pred_train = [1 if x>threshold else 0 for x in pred_train_unadjust]\n",
    "    pred_test = [1 if x>threshold else 0 for x in pred_test_unadjust]\n",
    "    print(\"f1: \" ,f1_score(y_train, pred_train))\n",
    "    display(create_2x2_matrix(y_train, pred_train))\n",
    "    # print_2x2_miss_pred(y_train, pred_train,x_train)\n",
    "    print('---------------------------------')\n",
    "    print('test')\n",
    "\n",
    "    print(\"f1: \",f1_score(y_test, pred_test))\n",
    "    display(create_2x2_matrix(y_test, pred_test))\n",
    "    train_miss = print_2x2_miss_pred(true_y=y_train,pred_y=pred_train,df=x_train)\n",
    "    test_miss =  print_2x2_miss_pred(true_y=y_test, pred_y=pred_test,df=x_test)\n",
    "    return {\n",
    "        \"miss_train_df\":train_miss, \n",
    "        \"miss_test_df\":test_miss,\n",
    "        \"x_train\":x_train,\n",
    "        \"y_train\":y_train,\n",
    "        \"x_test\":x_test,\n",
    "        \"y_test\":y_test,\n",
    "        \"pred_train\":pred_train,\n",
    "        \"pred_test\":pred_test,\n",
    "        \"model\":svm,\n",
    "        \"pred_train_un\":pred_train_unadjust,\n",
    "        \"pred_test_un\":pred_test_unadjust,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_2x2_matrix(true_y, pred_y):\n",
    "    matrix = np.zeros(4)\n",
    "\n",
    "    for t,p in zip(true_y, pred_y):\n",
    "        if t==0:\n",
    "            if p==0:matrix[0]+=1\n",
    "            if p==1:matrix[1]+=1\n",
    "        elif t==1:\n",
    "            if p==0:matrix[2]+=1\n",
    "            if p==1:matrix[3]+=1\n",
    "    return matrix.reshape(2,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_2x2_miss_pred(true_y, pred_y,df, test=True):\n",
    "    def print_str_label(num):\n",
    "        if num==1:return \"悪口\"\n",
    "        if num==0:return \"皮肉or その他\"\n",
    "        return np.nan\n",
    "\n",
    "    idx_arr = []\n",
    "    pred_judge=[]\n",
    "    true_judge=[]\n",
    "    col=[\"content\", \"pred_idx\", \"pred_label\",\"true_idx\", \"true_label\"]\n",
    "    returndf = pd.DataFrame(columns=col)\n",
    "    for i in range(len(df)):\n",
    "        if pred_y[i]!=true_y.values[i]:\n",
    "            tmpdf = pd.DataFrame(np.array([df.iloc[i].content, pred_y[i], print_str_label(pred_y[i]),\\\n",
    "                                            true_y.values[i], print_str_label(true_y.values[i])]).reshape(1,-1), \\\n",
    "                                              columns=col)\n",
    "            returndf = pd.concat([returndf, tmpdf])\n",
    "    return returndf\n",
    "\n",
    "\n",
    "def print_2x2_correct_pred(true_y, pred_y,df, test=True):\n",
    "    def print_str_label(num):\n",
    "        if num==1:return \"悪口\"\n",
    "        if num==0:return \"皮肉or その他\"\n",
    "        return np.nan\n",
    "\n",
    "    idx_arr = []\n",
    "    pred_judge=[]\n",
    "    true_judge=[]\n",
    "    col=[\"content\", \"pred_idx\", \"pred_label\",\"true_idx\", \"true_label\"]\n",
    "    returndf = pd.DataFrame(columns=col)\n",
    "    for i in range(len(df)):\n",
    "        if pred_y[i]==true_y.values[i]:\n",
    "            tmpdf = pd.DataFrame(np.array([df.iloc[i].content, pred_y[i], print_str_label(pred_y[i]),\\\n",
    "                                            true_y.values[i], print_str_label(true_y.values[i])]).reshape(1,-1), \\\n",
    "                                              columns=col)\n",
    "            returndf = pd.concat([returndf, tmpdf])\n",
    "    return returndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wakati_content(text):\n",
    "    wakati = []\n",
    "    for t in tokenizer.tokenize(text):\n",
    "        wakati.append(t.surface)\n",
    "    return wakati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from tqdm import tqdm\n",
    "# # data = pd.read_csv('../data/clean/mount_bad_list.csv')\n",
    "# data = pd.read_csv(\"../data/clean/mount_all_data.csv\")\n",
    "# data = data[data.type==1]\n",
    "wakati_arr = []\n",
    "# for r in tqdm(data.iterrows()):\n",
    "#     wakati = create_wakati_content(r[1].content)\n",
    "#     wakati_arr.append(wakati)\n",
    "# model = Word2Vec(wakati_arr, sg=1, size=100, window=5, min_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv('../data/some_comment_data.csv')\n",
    "\n",
    "# for r in tqdm(data.iterrows()):\n",
    "#     wakati = create_wakati_content(r[1].content)\n",
    "#     wakati_arr.append(wakati)\n",
    "# model = Word2Vec(wakati_arr, sg=1, size=100, window=5, min_count=1)\n",
    "# model.save(\"./word2vecModel/200000.model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec.load(\"./word2vecModel/100000.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1929it [00:15, 121.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>mophologics_num</th>\n",
       "      <th>bad_count_in_mophologic</th>\n",
       "      <th>simple_bad_flg</th>\n",
       "      <th>target</th>\n",
       "      <th>order</th>\n",
       "      <th>mophologic_content</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>なにこの糞ゲー</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[なに, この, 糞, ゲー]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ちょっと蛇足気味だな・・・</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[ちょっと, 蛇足, 気味, だ, な, ・, ・, ・]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         content  mophologics_num  bad_count_in_mophologic  simple_bad_flg  \\\n",
       "0        なにこの糞ゲー              4.0                      1.0               1   \n",
       "1  ちょっと蛇足気味だな・・・              8.0                      1.0               1   \n",
       "\n",
       "   target  order             mophologic_content  id  \n",
       "0       1      0                [なに, この, 糞, ゲー]   0  \n",
       "1       1      0  [ちょっと, 蛇足, 気味, だ, な, ・, ・, ・]   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1929, 8)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "悪口ワードの含有\n",
    "皮肉ワードの含有\n",
    "ポジティブワードの含有\n",
    "\n",
    "[形態素解析した時の単語数],[単純に悪口単語が文章に含まれているのかのフラグ], [形態素ごとに現れる悪口数]\n",
    "[皮肉単語が含まれているかのフラグ],[形態素ごとに現れる皮肉数]\n",
    "[ポジティブな単語が含まれているかのフラグ], [形態素ごとに現れるポジティブ単語数]\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "# df = bad.copy()\n",
    "# df = pd.concat([hiniku_, normal])\n",
    "# df = pd.concat([bad, df])\n",
    "import sys\n",
    "import numpy as np\n",
    "from janome.tokenizer import Tokenizer\n",
    "from tqdm import tqdm\n",
    "import gensim\n",
    "\n",
    "df = pd.read_csv('../data/clean/mount_all_data.csv')\n",
    "df.drop('comment_id', axis=1, inplace=True)\n",
    "tokenizer = Tokenizer()\n",
    "#悪口が含まれている数のカウント, 単に含まれているのかのフラグを返す\n",
    "def get_word_count(text, wordlist):\n",
    "    textlist = []\n",
    "    count=0\n",
    "    flg=0\n",
    "    for t in tokenizer.tokenize(text):\n",
    "        if t.surface in wordlist:\n",
    "            count+=1\n",
    "    for w in wordlist:\n",
    "        if w in text:\n",
    "            flg=1\n",
    "            return count, flg\n",
    "    \n",
    "    return count,flg\n",
    "\n",
    "\n",
    "def get_order_label(text):\n",
    "    for t in tokenizer.tokenize(text):\n",
    "        if t.infl_form[:2]==\"命令\":\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "def cos_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "\n",
    "'''\n",
    "###ここを実行することでword2vecのモデル作成\n",
    "from gensim.models import Word2Vec\n",
    "data = pd.read_csv('../data/some_comment_data.csv')\n",
    "newdata=pd.concat([pd.DataFrame(data.content), pd.DataFrame(df.content)])\n",
    "wakati_arr = []\n",
    "for r in tqdm(newdata.iterrows()):\n",
    "    wakati = create_wakati_content(r[1].content)\n",
    "    wakati_arr.append(wakadti)\n",
    "model = Word2Vec(wakati_arr, sg=1, size=100, window=5, min_count=1)\n",
    "'''\n",
    "\n",
    "def calc_cosine_similary(text,model,debug=False):\n",
    "    text_list = []\n",
    "    scores = {}\n",
    "\n",
    "    for t in tokenizer.tokenize(text):\n",
    "        text_list.append(t.surface)\n",
    "    for word in text_list:\n",
    "        try:\n",
    "            vector1 = model.wv[word]\n",
    "            scores[word] = []\n",
    "            for bad in bad_list:\n",
    "                try:\n",
    "                    vector2 = model.wv[bad]\n",
    "                    score = cos_similarity(vector1,vector2)\n",
    "                    scores[word].append(score)\n",
    "                except :\n",
    "                    pass\n",
    "        except:\n",
    "            pass\n",
    "    all_scores = []\n",
    "    for scores in scores.values():\n",
    "        all_scores +=scores\n",
    "    all_scores= np.array(all_scores)\n",
    "    typicalV = np.median(all_scores, axis=0)\n",
    "\n",
    "    if debug:\n",
    "        return scores\n",
    "    return typicalV\n",
    "\n",
    "\n",
    "def mophologicize(text):\n",
    "    words = []\n",
    "    for t in tokenizer.tokenize(text):\n",
    "        words.append(t.surface)    \n",
    "    return words\n",
    "\n",
    "\n",
    "#dfと悪口辞書を入れて新しい特徴量を含んだdfを返す\n",
    "def make_features(df, badwordlist, positivelist=np.nan, hinikulist=np.nan):\n",
    "#     col=[\"content\",\"mophologics_num\", \"bad_per_mophologic\", \"simple_bad_flg\",\"target\", \"hiniku_per_mophologic\",\\\n",
    "#          \"simple_hiniku_flg\", \"positive_per_mophologic\", \"simple_positive_flg\"]\n",
    "#     import gensim\n",
    "#     PATH=\"./gensimmodel/word2vec.gensim.model\"\n",
    "#     model = gensim.models.Word2Vec.load(PATH)\n",
    "    col=[\"content\",\"mophologics_num\", \"bad_count_in_mophologic\", \"simple_bad_flg\",\"target\",\"order\",\"mophologic_content\"]\n",
    "\n",
    "    basedf = pd.DataFrame(columns=col)\n",
    "    tokenizer = Tokenizer()\n",
    "    for r in tqdm(df.iterrows()):\n",
    "        text = str(r[1].content)\n",
    "        target = r[1].type\n",
    "        num = len(tokenizer.tokenize(text))\n",
    "        badcount,badflg = get_word_count(text, badwordlist)\n",
    "        orderlabel = get_order_label(text)\n",
    "        mophologic = mophologicize(text)\n",
    "#         hinikucount, hinikuflg = get_word_count(text, hinikulist)\n",
    "#         positivecount, positiveflg = get_word_count(text, positivelist)\n",
    "#         newdf = pd.DataFrame(np.array([text, num, badcount,badflg,target,\\\n",
    "#                                        hinikucount, hinikuflg, positivecount,\\\n",
    "#                                        positiveflg]).reshape(1,-1),columns=col)\n",
    "        newdf = pd.DataFrame(np.array([text, num, badcount,badflg,target, orderlabel,mophologic]).reshape(1,-1),columns=col)\n",
    "        basedf = pd.concat([basedf, newdf])\n",
    "\n",
    "    basedf[\"target\"] = basedf.apply(lambda x: int(x[\"target\"]), axis=1)\n",
    "#     basedf[\"comment_id\"] = basedf.index\n",
    "    basedf[\"bad_count_in_mophologic\"] = basedf.apply(lambda x: float(x[\"bad_count_in_mophologic\"]), axis=1)\n",
    "    basedf[\"mophologics_num\"] = basedf.apply(lambda x: float(x[\"mophologics_num\"]), axis=1)\n",
    "    basedf[\"order\"] = basedf.order.apply(lambda x: int(x))\n",
    "#     basedf[\"cosine_similar\"] = basedf.cosine_similar.apply(lambda x: float(x))\n",
    "    \n",
    "    return basedf\n",
    "df =make_features(df, list(badwordlist.bad.values))\n",
    "df = df.fillna(0.0)\n",
    "df = df.reset_index().drop('index', axis=1)\n",
    "df[\"id\"] = df.index\n",
    "display(df.head(2))\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bad_word_list():\n",
    "    b_l=[]\n",
    "    #wor2vecの辞書にない単語の除外\n",
    "    for word in badwordlist.bad.values:\n",
    "        try:\n",
    "            a = model.wv[word]\n",
    "            b_l.append(word)\n",
    "        except:\n",
    "            pass\n",
    "    return b_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col=[]\n",
    "for i in range(100):\n",
    "    col.append(\"f_\"+str(i))\n",
    "def create_mean_vector_data(df):\n",
    "\n",
    "    sandbox=pd.DataFrame(columns=col)\n",
    "    for r in tqdm(df.iterrows()):\n",
    "        text = r[1].mophologic_content\n",
    "        vec_list=[]\n",
    "        for t in text:\n",
    "                try:\n",
    "                    vec = model.wv[t]\n",
    "                    vec_list.append(vec)\n",
    "                except:\n",
    "                    vec_list.append(np.zeros(100))\n",
    "        vectors = pd.DataFrame(np.array(vec_list), columns=col)\n",
    "        tmp = pd.DataFrame(pd.DataFrame(vectors, columns=col).mean(axis=0)).T\n",
    "        sandbox = pd.concat([sandbox, tmp])\n",
    "        \n",
    "\n",
    "    sandbox.insert(0, \"target\",df.target.values)\n",
    "    sandbox.insert(1,\"content\",df.content.values)\n",
    "    return sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n"
     ]
    }
   ],
   "source": [
    "res1=train_and_pred(sandbox,threshold=0.23)sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_mean_vector_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>content</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>...</th>\n",
       "      <th>f_90</th>\n",
       "      <th>f_91</th>\n",
       "      <th>f_92</th>\n",
       "      <th>f_93</th>\n",
       "      <th>f_94</th>\n",
       "      <th>f_95</th>\n",
       "      <th>f_96</th>\n",
       "      <th>f_97</th>\n",
       "      <th>f_98</th>\n",
       "      <th>f_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>なにこの糞ゲー</td>\n",
       "      <td>0.171568</td>\n",
       "      <td>0.094425</td>\n",
       "      <td>-0.243519</td>\n",
       "      <td>-0.052515</td>\n",
       "      <td>-0.070759</td>\n",
       "      <td>0.411506</td>\n",
       "      <td>-0.151271</td>\n",
       "      <td>0.049143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192252</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>0.412266</td>\n",
       "      <td>-0.066477</td>\n",
       "      <td>0.105831</td>\n",
       "      <td>-0.042882</td>\n",
       "      <td>0.257228</td>\n",
       "      <td>0.351142</td>\n",
       "      <td>-0.161795</td>\n",
       "      <td>-0.213026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ちょっと蛇足気味だな・・・</td>\n",
       "      <td>-0.043816</td>\n",
       "      <td>0.080323</td>\n",
       "      <td>-0.144619</td>\n",
       "      <td>-0.005080</td>\n",
       "      <td>0.173006</td>\n",
       "      <td>0.395386</td>\n",
       "      <td>-0.056568</td>\n",
       "      <td>0.039275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263620</td>\n",
       "      <td>-0.129886</td>\n",
       "      <td>0.359296</td>\n",
       "      <td>-0.119541</td>\n",
       "      <td>0.160785</td>\n",
       "      <td>-0.061619</td>\n",
       "      <td>0.276749</td>\n",
       "      <td>0.451937</td>\n",
       "      <td>-0.257912</td>\n",
       "      <td>-0.222234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>蛇足は同意</td>\n",
       "      <td>0.208156</td>\n",
       "      <td>0.006126</td>\n",
       "      <td>-0.132161</td>\n",
       "      <td>-0.044880</td>\n",
       "      <td>0.013240</td>\n",
       "      <td>0.201669</td>\n",
       "      <td>-0.085165</td>\n",
       "      <td>0.097970</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037020</td>\n",
       "      <td>-0.047831</td>\n",
       "      <td>0.301364</td>\n",
       "      <td>0.015739</td>\n",
       "      <td>0.187576</td>\n",
       "      <td>0.087266</td>\n",
       "      <td>0.031497</td>\n",
       "      <td>0.311311</td>\n",
       "      <td>-0.030625</td>\n",
       "      <td>-0.046450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>蛇足っていってるヤツはJazzのライブを聞いたことがない奴</td>\n",
       "      <td>0.192251</td>\n",
       "      <td>0.026909</td>\n",
       "      <td>-0.158000</td>\n",
       "      <td>-0.141699</td>\n",
       "      <td>0.061730</td>\n",
       "      <td>0.190829</td>\n",
       "      <td>-0.010910</td>\n",
       "      <td>0.197090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072041</td>\n",
       "      <td>-0.172346</td>\n",
       "      <td>0.355718</td>\n",
       "      <td>0.091098</td>\n",
       "      <td>0.022344</td>\n",
       "      <td>-0.078946</td>\n",
       "      <td>0.181374</td>\n",
       "      <td>0.315143</td>\n",
       "      <td>-0.089571</td>\n",
       "      <td>0.001473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>蛇足っつう～かﾗｲﾌﾞｱﾚﾝｼﾞのお約束みたいなもんだろ</td>\n",
       "      <td>0.161773</td>\n",
       "      <td>-0.037911</td>\n",
       "      <td>-0.236227</td>\n",
       "      <td>-0.164525</td>\n",
       "      <td>-0.029755</td>\n",
       "      <td>0.214892</td>\n",
       "      <td>-0.170693</td>\n",
       "      <td>-0.051191</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127900</td>\n",
       "      <td>-0.149476</td>\n",
       "      <td>0.190359</td>\n",
       "      <td>0.028135</td>\n",
       "      <td>0.175896</td>\n",
       "      <td>-0.048945</td>\n",
       "      <td>0.095601</td>\n",
       "      <td>0.192192</td>\n",
       "      <td>-0.305131</td>\n",
       "      <td>-0.225195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>動画もいいな</td>\n",
       "      <td>0.260085</td>\n",
       "      <td>-0.001982</td>\n",
       "      <td>-0.463291</td>\n",
       "      <td>-0.092470</td>\n",
       "      <td>-0.009754</td>\n",
       "      <td>0.158714</td>\n",
       "      <td>-0.216898</td>\n",
       "      <td>0.039007</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214941</td>\n",
       "      <td>-0.445160</td>\n",
       "      <td>0.296062</td>\n",
       "      <td>-0.037287</td>\n",
       "      <td>0.100892</td>\n",
       "      <td>-0.101708</td>\n",
       "      <td>0.252462</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>-0.169833</td>\n",
       "      <td>-0.137619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3桁記念かきこ</td>\n",
       "      <td>0.196400</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>-0.191610</td>\n",
       "      <td>-0.135905</td>\n",
       "      <td>0.071396</td>\n",
       "      <td>0.116956</td>\n",
       "      <td>-0.148527</td>\n",
       "      <td>0.038829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106778</td>\n",
       "      <td>-0.094532</td>\n",
       "      <td>0.104275</td>\n",
       "      <td>0.090057</td>\n",
       "      <td>0.201584</td>\n",
       "      <td>-0.028431</td>\n",
       "      <td>-0.109992</td>\n",
       "      <td>0.199174</td>\n",
       "      <td>-0.179325</td>\n",
       "      <td>-0.132668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>鳥肌やばい</td>\n",
       "      <td>0.277268</td>\n",
       "      <td>0.229609</td>\n",
       "      <td>-0.306203</td>\n",
       "      <td>-0.279015</td>\n",
       "      <td>0.150056</td>\n",
       "      <td>0.260009</td>\n",
       "      <td>-0.122000</td>\n",
       "      <td>0.095843</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.360716</td>\n",
       "      <td>-0.207681</td>\n",
       "      <td>0.392508</td>\n",
       "      <td>-0.087436</td>\n",
       "      <td>-0.004210</td>\n",
       "      <td>-0.171299</td>\n",
       "      <td>0.110205</td>\n",
       "      <td>0.402899</td>\n",
       "      <td>-0.220459</td>\n",
       "      <td>-0.147590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>兄弟愛に泣いた</td>\n",
       "      <td>0.189268</td>\n",
       "      <td>0.067153</td>\n",
       "      <td>-0.251199</td>\n",
       "      <td>-0.267033</td>\n",
       "      <td>0.084082</td>\n",
       "      <td>0.251470</td>\n",
       "      <td>-0.121412</td>\n",
       "      <td>0.144522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.222742</td>\n",
       "      <td>-0.417797</td>\n",
       "      <td>0.305011</td>\n",
       "      <td>0.048205</td>\n",
       "      <td>-0.001763</td>\n",
       "      <td>-0.026853</td>\n",
       "      <td>0.152260</td>\n",
       "      <td>0.296517</td>\n",
       "      <td>-0.269014</td>\n",
       "      <td>-0.083580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>もう泣きそうなんだが</td>\n",
       "      <td>0.176374</td>\n",
       "      <td>-0.145087</td>\n",
       "      <td>-0.270334</td>\n",
       "      <td>-0.275965</td>\n",
       "      <td>0.089416</td>\n",
       "      <td>0.157621</td>\n",
       "      <td>-0.170482</td>\n",
       "      <td>0.210645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.176251</td>\n",
       "      <td>-0.135716</td>\n",
       "      <td>0.399351</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>-0.034332</td>\n",
       "      <td>-0.098282</td>\n",
       "      <td>0.342410</td>\n",
       "      <td>0.281634</td>\n",
       "      <td>-0.309258</td>\n",
       "      <td>-0.131956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1929 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    target                        content       f_0       f_1       f_2  \\\n",
       "0        1                        なにこの糞ゲー  0.171568  0.094425 -0.243519   \n",
       "0        1                  ちょっと蛇足気味だな・・・ -0.043816  0.080323 -0.144619   \n",
       "0        1                          蛇足は同意  0.208156  0.006126 -0.132161   \n",
       "0        1  蛇足っていってるヤツはJazzのライブを聞いたことがない奴  0.192251  0.026909 -0.158000   \n",
       "0        1   蛇足っつう～かﾗｲﾌﾞｱﾚﾝｼﾞのお約束みたいなもんだろ  0.161773 -0.037911 -0.236227   \n",
       "..     ...                            ...       ...       ...       ...   \n",
       "0        0                         動画もいいな  0.260085 -0.001982 -0.463291   \n",
       "0        0                        3桁記念かきこ  0.196400  0.001033 -0.191610   \n",
       "0        0                          鳥肌やばい  0.277268  0.229609 -0.306203   \n",
       "0        0                        兄弟愛に泣いた  0.189268  0.067153 -0.251199   \n",
       "0        0                     もう泣きそうなんだが  0.176374 -0.145087 -0.270334   \n",
       "\n",
       "         f_3       f_4       f_5       f_6       f_7  ...      f_90      f_91  \\\n",
       "0  -0.052515 -0.070759  0.411506 -0.151271  0.049143  ... -0.192252  0.003019   \n",
       "0  -0.005080  0.173006  0.395386 -0.056568  0.039275  ... -0.263620 -0.129886   \n",
       "0  -0.044880  0.013240  0.201669 -0.085165  0.097970  ...  0.037020 -0.047831   \n",
       "0  -0.141699  0.061730  0.190829 -0.010910  0.197090  ... -0.072041 -0.172346   \n",
       "0  -0.164525 -0.029755  0.214892 -0.170693 -0.051191  ... -0.127900 -0.149476   \n",
       "..       ...       ...       ...       ...       ...  ...       ...       ...   \n",
       "0  -0.092470 -0.009754  0.158714 -0.216898  0.039007  ... -0.214941 -0.445160   \n",
       "0  -0.135905  0.071396  0.116956 -0.148527  0.038829  ... -0.106778 -0.094532   \n",
       "0  -0.279015  0.150056  0.260009 -0.122000  0.095843  ... -0.360716 -0.207681   \n",
       "0  -0.267033  0.084082  0.251470 -0.121412  0.144522  ... -0.222742 -0.417797   \n",
       "0  -0.275965  0.089416  0.157621 -0.170482  0.210645  ... -0.176251 -0.135716   \n",
       "\n",
       "        f_92      f_93      f_94      f_95      f_96      f_97      f_98  \\\n",
       "0   0.412266 -0.066477  0.105831 -0.042882  0.257228  0.351142 -0.161795   \n",
       "0   0.359296 -0.119541  0.160785 -0.061619  0.276749  0.451937 -0.257912   \n",
       "0   0.301364  0.015739  0.187576  0.087266  0.031497  0.311311 -0.030625   \n",
       "0   0.355718  0.091098  0.022344 -0.078946  0.181374  0.315143 -0.089571   \n",
       "0   0.190359  0.028135  0.175896 -0.048945  0.095601  0.192192 -0.305131   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "0   0.296062 -0.037287  0.100892 -0.101708  0.252462  0.409400 -0.169833   \n",
       "0   0.104275  0.090057  0.201584 -0.028431 -0.109992  0.199174 -0.179325   \n",
       "0   0.392508 -0.087436 -0.004210 -0.171299  0.110205  0.402899 -0.220459   \n",
       "0   0.305011  0.048205 -0.001763 -0.026853  0.152260  0.296517 -0.269014   \n",
       "0   0.399351  0.000592 -0.034332 -0.098282  0.342410  0.281634 -0.309258   \n",
       "\n",
       "        f_99  \n",
       "0  -0.213026  \n",
       "0  -0.222234  \n",
       "0  -0.046450  \n",
       "0   0.001473  \n",
       "0  -0.225195  \n",
       "..       ...  \n",
       "0  -0.137619  \n",
       "0  -0.132668  \n",
       "0  -0.147590  \n",
       "0  -0.083580  \n",
       "0  -0.131956  \n",
       "\n",
       "[1929 rows x 102 columns]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mean_cosine_sim_data(df):\n",
    "    b_l=create_bad_word_list()\n",
    "    base = pd.DataFrame(columns=np.array(b_l))\n",
    "    \n",
    "    for r in tqdm(df.iterrows()):\n",
    "        text = r[1].mophologic_content\n",
    "        ave_list=[]\n",
    "\n",
    "        for word in b_l:\n",
    "            try:\n",
    "                v1 = model.wv[word]\n",
    "                cos_list = []\n",
    "                for t in text:\n",
    "                        v2=model.wv[t]\n",
    "                        cos_list.append(cos_similarity(v1,v2))\n",
    "                        if word not in b_l:\n",
    "                            b_l.append(word)\n",
    "            except:\n",
    "                pass\n",
    "            ave_list.append(np.array(cos_list).mean())\n",
    "        tmp=pd.DataFrame(np.array(ave_list).reshape(1,-1), columns=b_l)\n",
    "        base=pd.concat([base, tmp])\n",
    "        \n",
    "    base[\"target\"] =df.target.values\n",
    "    base[\"content\"] = df.content.values\n",
    "    base = base.loc[:,base.columns[::-1]]\n",
    "\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1929it [00:56, 34.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>はげ</th>\n",
       "      <th>キモオタ</th>\n",
       "      <th>バカー</th>\n",
       "      <th>きしょい</th>\n",
       "      <th>クソゲー</th>\n",
       "      <th>クソムシ</th>\n",
       "      <th>きらい</th>\n",
       "      <th>gm</th>\n",
       "      <th>...</th>\n",
       "      <th>シカト</th>\n",
       "      <th>ゆとり</th>\n",
       "      <th>ダサい</th>\n",
       "      <th>死ね</th>\n",
       "      <th>KY</th>\n",
       "      <th>イタイ</th>\n",
       "      <th>ばっか</th>\n",
       "      <th>ヘタ</th>\n",
       "      <th>蛇足</th>\n",
       "      <th>糞</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>なにこの糞ゲー</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737712</td>\n",
       "      <td>0.585149</td>\n",
       "      <td>0.553066</td>\n",
       "      <td>0.503287</td>\n",
       "      <td>0.660441</td>\n",
       "      <td>0.685455</td>\n",
       "      <td>0.790680</td>\n",
       "      <td>0.616264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>0.808434</td>\n",
       "      <td>0.770303</td>\n",
       "      <td>0.681981</td>\n",
       "      <td>0.660041</td>\n",
       "      <td>0.673967</td>\n",
       "      <td>0.833161</td>\n",
       "      <td>0.694381</td>\n",
       "      <td>0.698025</td>\n",
       "      <td>0.844980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ちょっと蛇足気味だな・・・</td>\n",
       "      <td>1</td>\n",
       "      <td>0.670004</td>\n",
       "      <td>0.588808</td>\n",
       "      <td>0.553636</td>\n",
       "      <td>0.499966</td>\n",
       "      <td>0.630143</td>\n",
       "      <td>0.643968</td>\n",
       "      <td>0.664984</td>\n",
       "      <td>0.602853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588668</td>\n",
       "      <td>0.682783</td>\n",
       "      <td>0.706425</td>\n",
       "      <td>0.545869</td>\n",
       "      <td>0.592983</td>\n",
       "      <td>0.637162</td>\n",
       "      <td>0.679401</td>\n",
       "      <td>0.664682</td>\n",
       "      <td>0.654728</td>\n",
       "      <td>0.703167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>蛇足は同意</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833095</td>\n",
       "      <td>0.794032</td>\n",
       "      <td>0.705397</td>\n",
       "      <td>0.689864</td>\n",
       "      <td>0.834422</td>\n",
       "      <td>0.844973</td>\n",
       "      <td>0.823597</td>\n",
       "      <td>0.822670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774778</td>\n",
       "      <td>0.816561</td>\n",
       "      <td>0.865877</td>\n",
       "      <td>0.677959</td>\n",
       "      <td>0.799566</td>\n",
       "      <td>0.823735</td>\n",
       "      <td>0.757569</td>\n",
       "      <td>0.806733</td>\n",
       "      <td>0.857879</td>\n",
       "      <td>0.779104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         content  target        はげ      キモオタ       バカー      きしょい      クソゲー  \\\n",
       "0        なにこの糞ゲー       1  0.737712  0.585149  0.553066  0.503287  0.660441   \n",
       "0  ちょっと蛇足気味だな・・・       1  0.670004  0.588808  0.553636  0.499966  0.630143   \n",
       "0          蛇足は同意       1  0.833095  0.794032  0.705397  0.689864  0.834422   \n",
       "\n",
       "       クソムシ       きらい        gm  ...       シカト       ゆとり       ダサい        死ね  \\\n",
       "0  0.685455  0.790680  0.616264  ...  0.596774  0.808434  0.770303  0.681981   \n",
       "0  0.643968  0.664984  0.602853  ...  0.588668  0.682783  0.706425  0.545869   \n",
       "0  0.844973  0.823597  0.822670  ...  0.774778  0.816561  0.865877  0.677959   \n",
       "\n",
       "         KY       イタイ       ばっか        ヘタ        蛇足         糞  \n",
       "0  0.660041  0.673967  0.833161  0.694381  0.698025  0.844980  \n",
       "0  0.592983  0.637162  0.679401  0.664682  0.654728  0.703167  \n",
       "0  0.799566  0.823735  0.757569  0.806733  0.857879  0.779104  \n",
       "\n",
       "[3 rows x 154 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_sim_df = create_mean_cosine_sim_data(df)\n",
    "mean_sim_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "f1:  0.7031914893617021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[273., 481.],\n",
       "       [ 77., 661.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "test\n",
      "f1:  0.6967213114754097\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 56., 124.],\n",
       "       [ 24., 170.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res2 = train_and_pred(mean_sim_df,threshold=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_the_highest_cosine_sim_data(df):\n",
    "    b_l = create_bad_word_list()\n",
    "    base = pd.DataFrame(columns=np.array(b_l))\n",
    "    \n",
    "    for r in tqdm(df.iterrows()):\n",
    "        text = r[1].mophologic_content\n",
    "        highest_list=[]\n",
    "\n",
    "        for word in b_l:\n",
    "            try:\n",
    "                v1 = model.wv[word]\n",
    "                cos_list = []\n",
    "                for t in text:\n",
    "                        v2=model.wv[t]\n",
    "                        cos_list.append(cos_similarity(v1,v2))\n",
    "                        if word not in b_l:\n",
    "                            b_l.append(word)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                highest_list.append(np.array(cos_list).max())\n",
    "            except:\n",
    "                highest_list.append(np.nan)\n",
    "        tmp=pd.DataFrame(np.array(highest_list).reshape(1,-1), columns=b_l)\n",
    "        base=pd.concat([base, tmp])\n",
    "        \n",
    "    base[\"target\"] =df.target.values\n",
    "    base[\"content\"] = df.content.values\n",
    "    base = base.loc[:,base.columns[::-1]]\n",
    "    return base\n",
    "\n",
    "# high_sim_df = create_the_highest_cosine_sim_data(df)\n",
    "# high_sim_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "f1:  0.7386489479512736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[353., 401.],\n",
       "       [ 71., 667.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "test\n",
      "f1:  0.7337526205450734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 72., 108.],\n",
       "       [ 19., 175.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res3 = train_and_pred(high_sim_df,threshold=0.26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1929, 103), (1866, 155), (1866, 155))"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1[\"df\"].shape,res2[\"df\"].shape,res2[\"df\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_id = list(res2[\"df\"].id.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1929/1929 [00:07<00:00, 267.30it/s]\n"
     ]
    }
   ],
   "source": [
    "newdf = pd.DataFrame(columns=df.columns)\n",
    "for i in tqdm(range(len(df))):\n",
    "    if i in valid_id:\n",
    "        tmp = pd.DataFrame(df.iloc[i]).T\n",
    "        newdf = pd.concat([newdf, tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1866it [00:06, 305.73it/s]\n",
      "1866it [00:42, 43.45it/s]\n",
      "1866it [00:45, 40.99it/s]\n"
     ]
    }
   ],
   "source": [
    "df1=create_mean_vector_data(newdf)\n",
    "df2=create_the_highest_cosine_sim_data(newdf)\n",
    "df3=create_mean_cosine_sim_data(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>はげ</th>\n",
       "      <th>キモオタ</th>\n",
       "      <th>バカー</th>\n",
       "      <th>きしょい</th>\n",
       "      <th>クソゲー</th>\n",
       "      <th>クソムシ</th>\n",
       "      <th>きらい</th>\n",
       "      <th>gm</th>\n",
       "      <th>...</th>\n",
       "      <th>シカト</th>\n",
       "      <th>ゆとり</th>\n",
       "      <th>ダサい</th>\n",
       "      <th>死ね</th>\n",
       "      <th>KY</th>\n",
       "      <th>イタイ</th>\n",
       "      <th>ばっか</th>\n",
       "      <th>ヘタ</th>\n",
       "      <th>蛇足</th>\n",
       "      <th>糞</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>なにこの糞ゲー</td>\n",
       "      <td>1</td>\n",
       "      <td>0.737712</td>\n",
       "      <td>0.585149</td>\n",
       "      <td>0.553066</td>\n",
       "      <td>0.503287</td>\n",
       "      <td>0.660441</td>\n",
       "      <td>0.685455</td>\n",
       "      <td>0.790680</td>\n",
       "      <td>0.616264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>0.808434</td>\n",
       "      <td>0.770303</td>\n",
       "      <td>0.681981</td>\n",
       "      <td>0.660041</td>\n",
       "      <td>0.673967</td>\n",
       "      <td>0.833161</td>\n",
       "      <td>0.694381</td>\n",
       "      <td>0.698025</td>\n",
       "      <td>0.844980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ちょっと蛇足気味だな・・・</td>\n",
       "      <td>1</td>\n",
       "      <td>0.670004</td>\n",
       "      <td>0.588808</td>\n",
       "      <td>0.553636</td>\n",
       "      <td>0.499966</td>\n",
       "      <td>0.630143</td>\n",
       "      <td>0.643968</td>\n",
       "      <td>0.664984</td>\n",
       "      <td>0.602853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588668</td>\n",
       "      <td>0.682783</td>\n",
       "      <td>0.706425</td>\n",
       "      <td>0.545869</td>\n",
       "      <td>0.592983</td>\n",
       "      <td>0.637162</td>\n",
       "      <td>0.679401</td>\n",
       "      <td>0.664682</td>\n",
       "      <td>0.654728</td>\n",
       "      <td>0.703167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>蛇足は同意</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833095</td>\n",
       "      <td>0.794032</td>\n",
       "      <td>0.705397</td>\n",
       "      <td>0.689864</td>\n",
       "      <td>0.834422</td>\n",
       "      <td>0.844973</td>\n",
       "      <td>0.823597</td>\n",
       "      <td>0.822670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774778</td>\n",
       "      <td>0.816561</td>\n",
       "      <td>0.865877</td>\n",
       "      <td>0.677959</td>\n",
       "      <td>0.799566</td>\n",
       "      <td>0.823735</td>\n",
       "      <td>0.757569</td>\n",
       "      <td>0.806733</td>\n",
       "      <td>0.857879</td>\n",
       "      <td>0.779104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>蛇足っていってるヤツはJazzのライブを聞いたことがない奴</td>\n",
       "      <td>1</td>\n",
       "      <td>0.706022</td>\n",
       "      <td>0.607392</td>\n",
       "      <td>0.528578</td>\n",
       "      <td>0.500326</td>\n",
       "      <td>0.686353</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.703343</td>\n",
       "      <td>0.653967</td>\n",
       "      <td>...</td>\n",
       "      <td>0.624809</td>\n",
       "      <td>0.752642</td>\n",
       "      <td>0.744694</td>\n",
       "      <td>0.605136</td>\n",
       "      <td>0.622628</td>\n",
       "      <td>0.693890</td>\n",
       "      <td>0.735393</td>\n",
       "      <td>0.672292</td>\n",
       "      <td>0.700866</td>\n",
       "      <td>0.706526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>蛇足っつう～かﾗｲﾌﾞｱﾚﾝｼﾞのお約束みたいなもんだろ</td>\n",
       "      <td>1</td>\n",
       "      <td>0.725199</td>\n",
       "      <td>0.641709</td>\n",
       "      <td>0.597139</td>\n",
       "      <td>0.570940</td>\n",
       "      <td>0.677702</td>\n",
       "      <td>0.670543</td>\n",
       "      <td>0.694109</td>\n",
       "      <td>0.645686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637345</td>\n",
       "      <td>0.738736</td>\n",
       "      <td>0.731107</td>\n",
       "      <td>0.628153</td>\n",
       "      <td>0.641106</td>\n",
       "      <td>0.709788</td>\n",
       "      <td>0.694881</td>\n",
       "      <td>0.699089</td>\n",
       "      <td>0.697893</td>\n",
       "      <td>0.721380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>動画もいいな</td>\n",
       "      <td>0</td>\n",
       "      <td>0.626146</td>\n",
       "      <td>0.517597</td>\n",
       "      <td>0.436151</td>\n",
       "      <td>0.419381</td>\n",
       "      <td>0.591118</td>\n",
       "      <td>0.590284</td>\n",
       "      <td>0.692273</td>\n",
       "      <td>0.561418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538685</td>\n",
       "      <td>0.716280</td>\n",
       "      <td>0.691977</td>\n",
       "      <td>0.615649</td>\n",
       "      <td>0.524166</td>\n",
       "      <td>0.610222</td>\n",
       "      <td>0.740473</td>\n",
       "      <td>0.604174</td>\n",
       "      <td>0.612987</td>\n",
       "      <td>0.712143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3桁記念かきこ</td>\n",
       "      <td>0</td>\n",
       "      <td>0.725750</td>\n",
       "      <td>0.689852</td>\n",
       "      <td>0.627817</td>\n",
       "      <td>0.582375</td>\n",
       "      <td>0.753787</td>\n",
       "      <td>0.745490</td>\n",
       "      <td>0.731255</td>\n",
       "      <td>0.744310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687163</td>\n",
       "      <td>0.720766</td>\n",
       "      <td>0.793534</td>\n",
       "      <td>0.541588</td>\n",
       "      <td>0.676400</td>\n",
       "      <td>0.746185</td>\n",
       "      <td>0.662057</td>\n",
       "      <td>0.735293</td>\n",
       "      <td>0.770483</td>\n",
       "      <td>0.659834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>鳥肌やばい</td>\n",
       "      <td>0</td>\n",
       "      <td>0.776060</td>\n",
       "      <td>0.602311</td>\n",
       "      <td>0.630515</td>\n",
       "      <td>0.517956</td>\n",
       "      <td>0.692731</td>\n",
       "      <td>0.695167</td>\n",
       "      <td>0.850130</td>\n",
       "      <td>0.658046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.635986</td>\n",
       "      <td>0.793466</td>\n",
       "      <td>0.815024</td>\n",
       "      <td>0.598607</td>\n",
       "      <td>0.697212</td>\n",
       "      <td>0.682221</td>\n",
       "      <td>0.814320</td>\n",
       "      <td>0.762895</td>\n",
       "      <td>0.725228</td>\n",
       "      <td>0.831501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>兄弟愛に泣いた</td>\n",
       "      <td>0</td>\n",
       "      <td>0.693602</td>\n",
       "      <td>0.580414</td>\n",
       "      <td>0.524677</td>\n",
       "      <td>0.441396</td>\n",
       "      <td>0.677969</td>\n",
       "      <td>0.655139</td>\n",
       "      <td>0.710792</td>\n",
       "      <td>0.646196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603326</td>\n",
       "      <td>0.741409</td>\n",
       "      <td>0.732368</td>\n",
       "      <td>0.559652</td>\n",
       "      <td>0.590555</td>\n",
       "      <td>0.685026</td>\n",
       "      <td>0.701540</td>\n",
       "      <td>0.681587</td>\n",
       "      <td>0.689233</td>\n",
       "      <td>0.692915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>もう泣きそうなんだが</td>\n",
       "      <td>0</td>\n",
       "      <td>0.634874</td>\n",
       "      <td>0.522841</td>\n",
       "      <td>0.466547</td>\n",
       "      <td>0.416720</td>\n",
       "      <td>0.589649</td>\n",
       "      <td>0.609288</td>\n",
       "      <td>0.653898</td>\n",
       "      <td>0.550669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552302</td>\n",
       "      <td>0.706724</td>\n",
       "      <td>0.684940</td>\n",
       "      <td>0.590654</td>\n",
       "      <td>0.539783</td>\n",
       "      <td>0.595131</td>\n",
       "      <td>0.735057</td>\n",
       "      <td>0.608613</td>\n",
       "      <td>0.608952</td>\n",
       "      <td>0.712907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1866 rows × 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          content target        はげ      キモオタ       バカー  \\\n",
       "0                         なにこの糞ゲー      1  0.737712  0.585149  0.553066   \n",
       "0                   ちょっと蛇足気味だな・・・      1  0.670004  0.588808  0.553636   \n",
       "0                           蛇足は同意      1  0.833095  0.794032  0.705397   \n",
       "0   蛇足っていってるヤツはJazzのライブを聞いたことがない奴      1  0.706022  0.607392  0.528578   \n",
       "0    蛇足っつう～かﾗｲﾌﾞｱﾚﾝｼﾞのお約束みたいなもんだろ      1  0.725199  0.641709  0.597139   \n",
       "..                            ...    ...       ...       ...       ...   \n",
       "0                          動画もいいな      0  0.626146  0.517597  0.436151   \n",
       "0                         3桁記念かきこ      0  0.725750  0.689852  0.627817   \n",
       "0                           鳥肌やばい      0  0.776060  0.602311  0.630515   \n",
       "0                         兄弟愛に泣いた      0  0.693602  0.580414  0.524677   \n",
       "0                      もう泣きそうなんだが      0  0.634874  0.522841  0.466547   \n",
       "\n",
       "        きしょい      クソゲー      クソムシ       きらい        gm  ...       シカト       ゆとり  \\\n",
       "0   0.503287  0.660441  0.685455  0.790680  0.616264  ...  0.596774  0.808434   \n",
       "0   0.499966  0.630143  0.643968  0.664984  0.602853  ...  0.588668  0.682783   \n",
       "0   0.689864  0.834422  0.844973  0.823597  0.822670  ...  0.774778  0.816561   \n",
       "0   0.500326  0.686353  0.686747  0.703343  0.653967  ...  0.624809  0.752642   \n",
       "0   0.570940  0.677702  0.670543  0.694109  0.645686  ...  0.637345  0.738736   \n",
       "..       ...       ...       ...       ...       ...  ...       ...       ...   \n",
       "0   0.419381  0.591118  0.590284  0.692273  0.561418  ...  0.538685  0.716280   \n",
       "0   0.582375  0.753787  0.745490  0.731255  0.744310  ...  0.687163  0.720766   \n",
       "0   0.517956  0.692731  0.695167  0.850130  0.658046  ...  0.635986  0.793466   \n",
       "0   0.441396  0.677969  0.655139  0.710792  0.646196  ...  0.603326  0.741409   \n",
       "0   0.416720  0.589649  0.609288  0.653898  0.550669  ...  0.552302  0.706724   \n",
       "\n",
       "         ダサい        死ね        KY       イタイ       ばっか        ヘタ        蛇足  \\\n",
       "0   0.770303  0.681981  0.660041  0.673967  0.833161  0.694381  0.698025   \n",
       "0   0.706425  0.545869  0.592983  0.637162  0.679401  0.664682  0.654728   \n",
       "0   0.865877  0.677959  0.799566  0.823735  0.757569  0.806733  0.857879   \n",
       "0   0.744694  0.605136  0.622628  0.693890  0.735393  0.672292  0.700866   \n",
       "0   0.731107  0.628153  0.641106  0.709788  0.694881  0.699089  0.697893   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "0   0.691977  0.615649  0.524166  0.610222  0.740473  0.604174  0.612987   \n",
       "0   0.793534  0.541588  0.676400  0.746185  0.662057  0.735293  0.770483   \n",
       "0   0.815024  0.598607  0.697212  0.682221  0.814320  0.762895  0.725228   \n",
       "0   0.732368  0.559652  0.590555  0.685026  0.701540  0.681587  0.689233   \n",
       "0   0.684940  0.590654  0.539783  0.595131  0.735057  0.608613  0.608952   \n",
       "\n",
       "           糞  \n",
       "0   0.844980  \n",
       "0   0.703167  \n",
       "0   0.779104  \n",
       "0   0.706526  \n",
       "0   0.721380  \n",
       "..       ...  \n",
       "0   0.712143  \n",
       "0   0.659834  \n",
       "0   0.831501  \n",
       "0   0.692915  \n",
       "0   0.712907  \n",
       "\n",
       "[1866 rows x 154 columns]"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "f1:  0.7496598639455783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[573., 181.],\n",
       "       [187., 551.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "test\n",
      "f1:  0.723404255319149\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[134.,  46.],\n",
       "       [ 58., 136.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "f1:  0.6666666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[566., 188.],\n",
       "       [275., 463.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "test\n",
      "f1:  0.6892655367231638\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[142.,  38.],\n",
       "       [ 72., 122.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "f1:  0.636429085673146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[545., 209.],\n",
       "       [296., 442.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "test\n",
      "f1:  0.6382978723404256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[118.,  62.],\n",
       "       [ 74., 120.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res1 = train_and_pred(df1)\n",
    "res2 = train_and_pred(df2)\n",
    "res3 = train_and_pred(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(res1, res2, res3,threshold=0.5):\n",
    "    train_ensemble = pd.DataFrame(np.array([res1[\"pred_train_un\"],res2[\"pred_train_un\"],res2[\"pred_train_un\"]]).sum(axis=0)/3,columns=[\"pred\"])\n",
    "    test_ensemble = pd.DataFrame(np.array([res1[\"pred_test_un\"],res2[\"pred_test_un\"],res2[\"pred_test_un\"]]).sum(axis=0)/3,columns=[\"pred\"])\n",
    "    train_ensemble = train_ensemble.pred.apply(lambda x: 1 if x>threshold else 0)\n",
    "    test_ensemble = test_ensemble.pred.apply(lambda x: 1 if x>threshold else 0)\n",
    "    train_score = f1_score(res1['y_train'], train_ensemble)\n",
    "    test_score = f1_score(res1['y_test'], test_ensemble)\n",
    "    return {\"train_score\":train_score,\n",
    "            \"test_score\":test_score,\n",
    "            \"pred_train\":train_ensemble,\n",
    "            \"pred_test\":test_ensemble\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "0.7402689313517339\n",
      "test:\n",
      "0.7645429362880886\n"
     ]
    }
   ],
   "source": [
    "res=ensemble(res1,res2,res3)\n",
    "print(\"train:\")\n",
    "print(res[\"train_score\"])\n",
    "print('test:')\n",
    "print(res[\"test_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-416-73fcda467bb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_2x2_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y_train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-d310d286f505>\u001b[0m in \u001b[0;36mcreate_2x2_matrix\u001b[0;34m(true_y, pred_y)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "create_2x2_matrix(true_y=res1[\"y_train\"], pred_y=tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08\n",
      "0.68700140778977 0.7007299270072994\n",
      "0.09\n",
      "0.6902738432483475 0.7047970479704797\n",
      "0.1\n",
      "0.6955280685061845 0.7050092764378479\n",
      "0.11\n",
      "0.6991869918699186 0.7063197026022305\n",
      "0.12\n",
      "0.7032227032227033 0.7076350093109869\n",
      "0.13\n",
      "0.7090820786789704 0.7102803738317756\n",
      "0.16\n",
      "0.7194458189015339 0.7137404580152672\n",
      "0.17\n",
      "0.7219463753723933 0.7153846153846154\n",
      "0.2\n",
      "0.7328940699442473 0.7173489278752436\n",
      "0.21\n",
      "0.7380830343413635 0.7215686274509804\n",
      "0.22\n",
      "0.739556472408458 0.7218934911242605\n",
      "0.23\n",
      "0.7419354838709676 0.7261904761904762\n",
      "0.24\n",
      "0.742289597490852 0.7334669338677355\n",
      "0.25\n",
      "0.7445795875198309 0.7413441955193483\n",
      "0.26\n",
      "0.746268656716418 0.7438016528925618\n",
      "0.27\n",
      "0.7508090614886731 0.7463312368972747\n",
      "0.31\n",
      "0.7655016910935737 0.7516198704103672\n",
      "0.32\n",
      "0.7666856816885339 0.7571115973741795\n",
      "0.34\n",
      "0.7745327102803737 0.7589285714285714\n",
      "0.35000000000000003\n",
      "0.7796810395747193 0.7629796839729119\n",
      "0.36\n",
      "0.7785714285714286 0.767123287671233\n",
      "0.47000000000000003\n",
      "0.7576374745417516 0.7688172043010753\n"
     ]
    }
   ],
   "source": [
    "line_score = 0.7\n",
    "for threshold in np.arange(0,1,0.01):\n",
    "    train_s, test_s=ensemble(res1,res2,res3,threshold)\n",
    "    if test_s>line_score:\n",
    "        line_score=test_s\n",
    "        print(threshold)\n",
    "        print(train_s, test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testdf = base.copy()\n",
    "# testdf = testdf.dropna()\n",
    "# # testdf.target = testdf.target.apply(lambda x: 0 if x==0 else 1)#x==0(ニュートラル)の時0, その他は1\n",
    "# testdf.target = testdf.target.apply(lambda x: 0 if x==1 else 1)#x==1(悪口)の時0, その他は1 [0:悪口, 1:その他]\n",
    "# # testdf.target = testdf.target.apply(lambda x: 0 if x==2 else 1)#x==2(皮肉)の時0, その他は1\n",
    "# testdf.target.unique()\n",
    "# testdf.target.unique()\n",
    "# X = testdf.drop(\"target\",axis=1)#.drop('content', axis=1)\n",
    "# y=testdf.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# 1対1で予測をする時\n",
    "# '''\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.metrics import f1_score\n",
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# def vectorize(x_train,x_test, vec):\n",
    "#     x_train_vec = vec.fit_transform(x_train.content)\n",
    "#     x_test_vec = vec.transform(x_test.content)\n",
    "    \n",
    "#     x_train_vec = pd.DataFrame(x_train_vec.todense())\n",
    "#     x_test_vec = pd.DataFrame(x_test_vec.todense())\n",
    "#     return x_train_vec,x_test_vec\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "def train_and_pred(df, threshold=0.5):\n",
    "    df.insert(0,\"id\",df.index)\n",
    "    \n",
    "    df = df.dropna()\n",
    "    # testdf.target = testdf.target.apply(lambda x: 0 if x==0 else 1)#x==0(ニュートラル)の時0, その他は1\n",
    "    df.target = df.target.apply(lambda x: 1 if x==1 else 0)#x==1(悪口)の時1, その他は0 [0:悪口, 1:その他]\n",
    "    # testdf.target = testdf.target.apply(lambda x: 0 if x==2 else 1)#x==2(皮肉)の時0, その他は1\n",
    "#     df.target.unique()\n",
    "#     df.target.unique()\n",
    "    X = df.drop(\"target\",axis=1)#.drop('content', axis=1)\n",
    "    y=df[[\"target\", \"id\"]]\n",
    "    \n",
    "    \n",
    "    svm = SVR()\n",
    "    svm.fit(x_train.drop(['content',\"id\"], axis=1), y_train.target)\n",
    "    pred_train = svm.predict(x_train.drop(['content',\"id\"], axis=1))\n",
    "    pred_test = svm.predict(x_test.drop(['content',\"id\"], axis=1))\n",
    "\n",
    "    print(\"train\")\n",
    "\n",
    "    pred_train = [1 if x>threshold else 0 for x in pred_train]\n",
    "    pred_test = [1 if x>threshold else 0 for x in pred_test]\n",
    "    print(\"f1: \" ,f1_score(y_train, pred_train))\n",
    "    display(create_2x2_matrix(y_train, pred_train))\n",
    "    # print_2x2_miss_pred(y_train, pred_train,x_train)\n",
    "    print('----------------------------')\n",
    "    print('test')\n",
    "\n",
    "    print(\"f1: \",f1_score(y_test, pred_test))\n",
    "    display(create_2x2_matrix(y_test, pred_test))\n",
    "    train_miss = print_2x2_miss_pred(y_train, pred_train,x_train)\n",
    "    test_miss =  print_2x2_miss_pred(true_y=y_test, pred_y=pred_test,df=x_test)\n",
    "    return {\n",
    "        \"miss_train_df\":train_miss, \n",
    "        \"miss_test_df\":test_miss,\n",
    "        \"x_train\":x_train,\n",
    "        \"y_train\":y_train,\n",
    "        \"x_test\":x_test,\n",
    "        \"y_test\":y_test,\n",
    "        \"pred_train\":pred_train,\n",
    "        \"pred_test\":pred_test\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVR\n",
    "# svm = SVR()\n",
    "\n",
    "# # svm.fit(x_train_vec, y_train)\n",
    "# # pred_train = svm.predict(x_train_vec)\n",
    "# # pred_test = svm.predict(x_test_vec)\n",
    "\n",
    "\n",
    "# # svm.fit(x_train.drop(['content',\"cosine_similary\"], axis=1), y_train)\n",
    "# # pred_train = svm.predict(x_train.drop(['content',\"cosine_similary\"], axis=1))\n",
    "# # pred_test = svm.predict(x_test.drop(['content',\"cosine_similary\"], axis=1))\n",
    "\n",
    "\n",
    "# svm.fit(x_train.drop(['content'], axis=1), y_train)\n",
    "# pred_train = svm.predict(x_train.drop(['content'], axis=1))\n",
    "# pred_test = svm.predict(x_test.drop(['content'], axis=1))\n",
    "\n",
    "# print(\"train\")\n",
    "\n",
    "# pred_train = [1 if x>0.899 else 0 for x in pred_train]\n",
    "# pred_test = [1 if x>0.899 else 0 for x in pred_test]\n",
    "# print(f1_score(y_train, pred_train))\n",
    "# display(create_2x2_matrix(y_train, pred_train))\n",
    "# # print_2x2_miss_pred(y_train, pred_train,x_train)\n",
    "# print('------------------------------------------------------------------')\n",
    "# print('test')\n",
    "\n",
    "# print(f1_score(y_test, pred_test))\n",
    "# display(create_2x2_matrix(y_test, pred_test))\n",
    "# # print_2x2_miss_pred(true_y=y_test, pred_y=pred_test,df=x_test).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_miss = print_2x2_miss_pred(y_train, pred_train,x_train)\n",
    "# test_miss =  print_2x2_miss_pred(true_y=y_test, pred_y=pred_test,df=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pred_df = print_2x2_pred_true(y_train, pred_train,x_train)\n",
    "# test_pred_df =  print_2x2_pred_true(true_y=y_test, pred_y=pred_test,df=x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "gbm = lgb.LGBMClassifier()\n",
    "# x_train.simple_bad_flg = x_train.simple_bad_flg.apply(lambda x: int(x))\n",
    "# x_test.simple_bad_flg = x_test.simple_bad_flg.apply(lambda x: int(x))\n",
    "# x_test.cosine_similar = x_test.cosine_similar.apply(lambda x: float(x))\n",
    "\n",
    "x_train = res3[\"x_train\"]\n",
    "y_train = res3[\"y_train\"]\n",
    "x_test = res3[\"x_test\"]\n",
    "y_test = res3[\"y_test\"]\n",
    "\n",
    "gbm.fit(x_train.drop('content',axis=1),y_train)\n",
    "pred_train = gbm.predict(x_train.drop('content',axis=1))\n",
    "pred_test = gbm.predict(x_test.drop('content',axis=1))\n",
    "\n",
    "# gbm.fit(x_train.drop(['content',\"cosine_similary\"],axis=1),y_train)\n",
    "# pred_train = gbm.predict(x_train.drop(['content',\"cosine_similary\"],axis=1))\n",
    "# pred_test = gbm.predict(x_test.drop(['content',\"cosine_similary\"],axis=1))\n",
    "'''\n",
    "train\n",
    "0.8698839340256568\n",
    "array([[618., 130.],\n",
    "       [ 83., 712.]])\n",
    "test\n",
    "0.919315403422983\n",
    "array([[165.,  19.],\n",
    "       [ 14., 188.]])\n",
    "'''\n",
    "\n",
    "# gbm.fit(x_train_vec, y_train)\n",
    "# pred_train = gbm.predict(x_train_vec)\n",
    "# pred_test = gbm.predict(x_test_vec)\n",
    "\n",
    "\n",
    "print(\"train\")\n",
    "print(f1_score(y_train, pred_train))\n",
    "display(create_2x2_matrix(y_train, pred_train))\n",
    "# print_2x2_miss_pred(y_train, pred_train,x_train).head()\n",
    "print('test')\n",
    "\n",
    "print(f1_score(y_test, pred_test))\n",
    "display(create_2x2_matrix(y_test, pred_test))\n",
    "# print_2x2_miss_pred(true_y=y_test, pred_y=pred_test,df=x_test).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# 1対その他での学習\n",
    "# \"\"\"\n",
    "\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.multiclass import OneVsRestClassifier\n",
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "\n",
    "# def vectorize(x_train,x_test, vec):\n",
    "#     x_train_vec = vec.fit_transform(x_train.content)\n",
    "#     x_test_vec = vec.transform(x_test.content)\n",
    "    \n",
    "#     x_train_vec = pd.DataFrame(x_train_vec.todense())\n",
    "#     x_test_vec = pd.DataFrame(x_test_vec.todense())\n",
    "    \n",
    "#     x_train_vec[\"comment_id\"]=x_train.comment_id.values\n",
    "#     x_test_vec[\"comment_id\"]=x_test.comment_id.values\n",
    "    \n",
    "#     return x_train_vec,x_test_vec\n",
    "\n",
    "\n",
    "\n",
    "# def train_and_predict(df):\n",
    "\n",
    "#     X = df.drop(\"target\",axis=1)\n",
    "#     y = df.target\n",
    "\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "    \n",
    "#     vec = TfidfVectorizer()\n",
    "#     x_train_vec, x_test_vec = vectorize(x_train, x_test, vec)\n",
    "#     train_content = pd.DataFrame(x_train.content.values, columns=[\"content\"])\n",
    "#     test_content  = pd.DataFrame(x_test.content.values, columns=[\"content\"])\n",
    "#     x_train.drop([\"content\"],axis=1,inplace=True)\n",
    "#     x_test.drop([\"content\"],axis=1,inplace=True)\n",
    "#     new_x_train = x_train.merge(x_train_vec, on=\"comment_id\")#.drop('comment_id',axis=1)\n",
    "#     new_x_test  = x_test.merge(x_test_vec, on=\"comment_id\")#.drop('comment_id',axis=1)\n",
    "#     new_x_train.drop('comment_id', axis=1, inplace=True)\n",
    "#     new_x_test.drop('comment_id', axis=1, inplace=True)\n",
    "#     x_train.drop([\"comment_id\"],axis=1,inplace=True)\n",
    "#     x_test.drop([\"comment_id\"],axis=1,inplace=True)\n",
    "\n",
    "#     svm = SVC(C=1.0, random_state=42)\n",
    "#     vec_model = OneVsRestClassifier(svm)\n",
    "#     vec_model.fit(new_x_train, y_train)\n",
    "#     model = OneVsRestClassifier(svm)\n",
    "#     model.fit(x_train, y_train)\n",
    "#     print('fin')\n",
    "\n",
    "#     return {\n",
    "#         \"pred_train_with_vec\":  vec_model.predict(new_x_train),\n",
    "#         \"pred_test_with_vec\": vec_model.predict(new_x_test),\n",
    "#         \"pred_train\":model.predict(x_train),\n",
    "#         \"pred_test\":model.predict(x_test),\n",
    "#         \"x_train\":x_train,\n",
    "#         \"new_x_train\":new_x_train,\n",
    "#         \"y_train\":y_train,\n",
    "#         \"new_x_test\":new_x_test,\n",
    "#         \"x_test\":x_test,\n",
    "#         \"y_test\":y_test,\n",
    "#         \"train_content\":train_content,\n",
    "#         \"test_content\":test_content,\n",
    "# #         \"x_train_vec\":x_train_vec,\n",
    "# #         \"x_test_vec\":x_test_vec\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import recall_score\n",
    "# from sklearn.metrics import precision_score\n",
    "# import numpy as np\n",
    "# '''\n",
    "# mxm,ここでは3x3のマトリックスを作成する\n",
    "# そこからf1値を計算する（同ディレクトリの画像参照）\n",
    "# '''\n",
    "\n",
    "# def create_3x3_matrix(true_y, pred_y):\n",
    "#     matrix = np.zeros(9)\n",
    "\n",
    "#     for t,p in zip(true_y, pred_y):\n",
    "#         if t==0:\n",
    "#             if p==0:matrix[0]+=1\n",
    "#             if p==1:matrix[1]+=1\n",
    "#             if p==2:matrix[2]+=1\n",
    "#         elif t==1:\n",
    "#             if p==0:matrix[3]+=1\n",
    "#             if p==1:matrix[4]+=1\n",
    "#             if p==2:matrix[5]+=1\n",
    "#         elif t==2:\n",
    "#             if p==0:matrix[6]+=1\n",
    "#             if p==1:matrix[7]+=1\n",
    "#             if p==2:matrix[8]+=1\n",
    "\n",
    "#     return matrix.reshape(3,3)\n",
    "# # matrix=create_3x3_matrix(y_train, pred_train)\n",
    "# # matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.to_csv('../data/clean/mount_data.csv', index=False)\n",
    "# df1.to_excel('../data/clean/mount_data.xlsx', index=False)\n",
    "# df1 = pd.read_excel('../data/clean/mount_data.xlsx')\n",
    "# df1 = df1.dropna()\n",
    "# df1[\"type\"]=df1.target\n",
    "# df1 = make_bad_feature(df1, badwordlist=badwordlist, positivelist=positivelist, hinikulist=hinikulist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1[df1.target==0].shape[0], df1[df1.target==1].shape[0],df1[df1.target==2].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# predのキー\n",
    "# dict_keys(['pred_train', 'pred_test', 'x_train', 'new_x_train', 'y_train',\\\n",
    "# 'new_x_test', 'x_test', 'y_test', 'train_content', 'test_content'])\n",
    "# '''\n",
    "\n",
    "# def print_3x3miss_pred(pred, test=True, true_y=np.nan, pred_y=np.nan,df=np.nan):\n",
    "#     if test:\n",
    "#         true_y = pred[\"y_test\"]\n",
    "#         pred_y = pred[\"pred_test\"]\n",
    "#         df     = pred[\"test_content\"]\n",
    "#     else:\n",
    "#         true_y = pred[\"y_train\"]\n",
    "#         pred_y = pred[\"pred_train\"]\n",
    "#         df     = pred[\"train_content\"]\n",
    "\n",
    "\n",
    "#     idx_arr = []\n",
    "#     pred_judge=[]\n",
    "#     true_judge=[]\n",
    "#     for i in range(len(pred_y)):\n",
    "#         if pred_y[i]!=true_y.values[i]:\n",
    "# #             print(pred[i], true_y.values[i])\n",
    "#             idx_arr.append(i)\n",
    "#             pred_judge.append(pred_y[i])\n",
    "#             true_judge.append(true_y.values[i])\n",
    "\n",
    "#     def print_str_label(num):\n",
    "#         if num==0:return \"ニュートラル\"\n",
    "#         if num==1:return \"悪口\"\n",
    "#         if num==2:return \"皮肉\"\n",
    "#         return np.nan\n",
    "    \n",
    "#     col=[\"content\",\"true_label_id\",\"true_label\",\"pred_label_id\",\"pred_label\"]\n",
    "#     miss_data = pd.DataFrame(columns=col)\n",
    "#     for i,idx in enumerate(idx_arr):\n",
    "#         tmpdf = pd.DataFrame(np.array([df.iloc[idx].content, true_judge[i],\\\n",
    "#                                           print_str_label(true_judge[i]), pred_judge[i],\\\n",
    "#                                         print_str_label(pred_judge[i])]).reshape(1,-1),columns=col)\n",
    "#         miss_data = pd.concat([miss_data, tmpdf])\n",
    "        \n",
    "# #             display(df.iloc[idx].content)\n",
    "# #             print('true label  *',true_judge[i] , (print_str_label(true_judge[i])))\n",
    "# #             print('pred label  *',pred_judge[i], (print_str_label(pred_judge[i])))\n",
    "# #             print(\"------------------------------------------------------------------------------------\")\n",
    "        \n",
    "#     print(miss_data.shape)\n",
    "#     return miss_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "他のベクトル変換の例\n",
    "\n",
    "x_train,x_test, y_train, y_test = train_test_split(content, target, random_state=42)\n",
    "\n",
    "・バイナリ\n",
    "vec = CountVectorizer(binary=True)\n",
    "train_and_val(x_train, x_test, y_train, y_test, vec)\n",
    "\n",
    "・カウント\n",
    "print('count')\n",
    "vec = CountVectorizer(binary=False)\n",
    "train_and_val(x_train, x_test, y_train, y_test, vec)\n",
    "\n",
    "\n",
    "・TfIdf\n",
    "vec = TfidfVectorizer()\n",
    "vectorize(x_train, x_test, y_train, y_test, vec)\n",
    "\n",
    "・bigram\n",
    "vec = TfidfVectorizer(ngram_range=(1,3))\n",
    "train_and_val(x_train, x_test, y_train, y_test, vec)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = train_and_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"no vectorize train\")\n",
    "# matrix=create_3x3_matrix(pred[\"y_train\"], pred[\"pred_train\"])\n",
    "# print(matrix)\n",
    "# print(calc_scores(matrix))\n",
    "# print()\n",
    "# print()\n",
    "# print('no vectoizer test')\n",
    "# matrix=create_3x3_matrix(pred[\"y_test\"], pred[\"pred_test\"])\n",
    "# print(matrix)\n",
    "# print(calc_scores(matrix))\n",
    "# print()\n",
    "# print()\n",
    "\n",
    "# print(\"vectorize train\")\n",
    "# matrix=create_3x3_matrix(pred[\"y_train\"], pred[\"pred_train_with_vec\"])\n",
    "# print(matrix)\n",
    "# print(calc_scores(matrix))\n",
    "# print()\n",
    "# print()\n",
    "# print('vectorize test')\n",
    "# matrix=create_3x3_matrix(pred[\"y_test\"], pred[\"pred_test_with_vec\"])\n",
    "# print(matrix)\n",
    "# print(calc_scores(matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1543, 386)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res1[\"pred_train\"]),len(res1[\"pred_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1492, 374)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res2[\"pred_train\"]),len(res2[\"pred_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1492, 374)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res3[\"pred_train\"]),len(res3[\"pred_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
