{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bad = pd.read_csv('../data/bad/bad.csv')\n",
    "normal=pd.read_csv('../data/neautral/neutral.csv')\n",
    "hiniku_=pd.read_csv('../data/hiniku/hiniku_with_word.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positivelist = list(hiniku_.dropna().positiveword.values)\n",
    "hinikulist = list(hiniku_.dropna().hinikuword.values)\n",
    "badwordlist = list(bad.word)#悪口単語をリストで抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "750it [00:06, 109.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "悪口ワードの含有\n",
    "皮肉ワードの含有\n",
    "ポジティブワードの含有\n",
    "\n",
    "[形態素解析した時の単語数],[単純に悪口単語が文章に含まれているのかのフラグ], [形態素ごとに現れる悪口数]\n",
    "[皮肉単語が含まれているかのフラグ],[形態素ごとに現れる皮肉数]\n",
    "[ポジティブな単語が含まれているかのフラグ], [形態素ごとに現れるポジティブ単語数]\n",
    "\n",
    "'''\n",
    "import pandas as pd\n",
    "# df = bad.copy()\n",
    "df = pd.concat([hiniku_, normal])\n",
    "df = pd.concat([bad, df])\n",
    "import sys\n",
    "sys.path.append('/Users/nagataeiki/.pyenv/versions/3.7.4/lib/python3.7/site-packages')\n",
    "import numpy as np\n",
    "from janome.tokenizer import Tokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "#悪口が含まれている数のカウント, 単に含まれているのかのフラグを返す\n",
    "def get_word_count(text, wordlist):\n",
    "    textlist = []\n",
    "    count=0\n",
    "    flg=0\n",
    "    for t in tokenizer.tokenize(text):\n",
    "        if t.surface in wordlist:\n",
    "            count+=1\n",
    "    for w in wordlist:\n",
    "        if w in text:\n",
    "            flg=1\n",
    "            return count, flg\n",
    "    \n",
    "    return count,flg\n",
    "\n",
    "\n",
    "#dfと悪口辞書を入れて新しい特徴量を含んだdfを返す\n",
    "def make_bad_feature(df, badwordlist, positivelist, hinikulist):\n",
    "    col=[\"content\",\"mophologics_num\", \"bad_per_mophologic\", \"simple_bad_flg\",\"target\", \"hiniku_per_mophologic\",\\\n",
    "         \"simple_hiniku_flg\", \"positive_per_mophologic\", \"simple_positive_flg\"]\n",
    "    basedf = pd.DataFrame(columns=col)\n",
    "    tokenizer = Tokenizer()\n",
    "    for r in tqdm(df.iterrows()):\n",
    "        text = str(r[1].content)\n",
    "        target = r[1].type\n",
    "        num = len(tokenizer.tokenize(text))\n",
    "        badcount,badflg = get_word_count(text, badwordlist)\n",
    "        hinikucount, hinikuflg = get_word_count(text, hinikulist)\n",
    "        positivecount, positiveflg = get_word_count(text, positivelist)\n",
    "        newdf = pd.DataFrame(np.array([text, num, badcount,badflg,target,\\\n",
    "                                       hinikucount, hinikuflg, positivecount,\\\n",
    "                                       positiveflg]).reshape(1,-1),columns=col)\n",
    "        basedf = pd.concat([basedf, newdf])\n",
    "\n",
    "    basedf[\"target\"] = basedf.apply(lambda x: int(x[\"target\"]), axis=1)\n",
    "    return basedf\n",
    "df =make_bad_feature(df, badwordlist, positivelist, hinikulist)\n",
    "df.head(2)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hiniku_ = pd.read_csv('../data/hiniku/hiniku_with_word.csv')\n",
    "\n",
    "# col=[\"content\",\"mophologics_num\", \"bad_word_num\", \"simple_bad_flg\",\"target\", \"hinikuword\", \"positiveword\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# 1対1で予測をする時\n",
    "# '''\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import f1_score\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "# svm = SVC(C=1.0, random_state=42)\n",
    "# svm.fit(x_train, y_train)\n",
    "\n",
    "# pred_train = svm.predict(x_train)\n",
    "# pred_test = svm.predict(x_test)\n",
    "# print(f1_score(y_train, pred_train))\n",
    "# print(f1_score(y_test, pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1対その他での学習\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def vectorize(x_train,x_test, vec):\n",
    "    x_train_vec = vec.fit_transform(x_train.content)\n",
    "    x_test_vec = vec.transform(x_test.content)\n",
    "    \n",
    "    x_train_vec = pd.DataFrame(x_train_vec.todense())\n",
    "    x_test_vec = pd.DataFrame(x_test_vec.todense())\n",
    "    \n",
    "    x_train_vec[\"comment_id\"]=x_train.comment_id.values\n",
    "    x_test_vec[\"comment_id\"]=x_test.comment_id.values\n",
    "    \n",
    "    return x_train_vec,x_test_vec\n",
    "\n",
    "\n",
    "\n",
    "def train_and_predict(df):\n",
    "\n",
    "    X = df.drop(\"target\",axis=1)\n",
    "    y = df.target\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "    \n",
    "    vec = TfidfVectorizer()\n",
    "    x_train_vec, x_test_vec = vectorize(x_train, x_test, vec)\n",
    "    x_train.drop(\"content\",axis=1,inplace=True)\n",
    "    x_test.drop(\"content\",axis=1,inplace=True)\n",
    "    new_x_train = x_train.merge(x_train_vec, on=\"comment_id\")#.drop('content',axis=1)\n",
    "    new_x_test  = x_test.merge(x_test_vec, on=\"comment_id\")#.drop('content',axis=1)\n",
    "    svm = SVC(C=1.0, random_state=42)\n",
    "    model = OneVsRestClassifier(svm)\n",
    "    model.fit(new_x_train, y_train)\n",
    "    print('fin')\n",
    "\n",
    "    return {\n",
    "        \"pred_train\":  model.predict(new_x_train),\n",
    "        \"pred_test\": model.predict(new_x_test),\n",
    "        \"x_train\":new_x_train,\n",
    "        \"y_train\":y_train,\n",
    "        \"x_test\":new_x_test,\n",
    "        \"y_test\":y_test,\n",
    "#         \"x_train_vec\":x_train_vec,\n",
    "#         \"x_test_vec\":x_test_vec\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "'''\n",
    "mxm,ここでは3x3のマトリックスを作成する\n",
    "そこからf1値を計算する（同ディレクトリの画像参照）\n",
    "'''\n",
    "\n",
    "def create_3x3_matrix(true_y, pred_y):\n",
    "    matrix = np.zeros(9)\n",
    "\n",
    "    for t,p in zip(true_y, pred_y):\n",
    "        if t==0:\n",
    "            if p==0:matrix[0]+=1\n",
    "            if p==1:matrix[1]+=1\n",
    "            if p==2:matrix[2]+=1\n",
    "        elif t==1:\n",
    "            if p==0:matrix[3]+=1\n",
    "            if p==1:matrix[4]+=1\n",
    "            if p==2:matrix[5]+=1\n",
    "        elif t==2:\n",
    "            if p==0:matrix[6]+=1\n",
    "            if p==1:matrix[7]+=1\n",
    "            if p==2:matrix[8]+=1\n",
    "\n",
    "    return matrix.reshape(3,3)\n",
    "# matrix=create_3x3_matrix(y_train, pred_train)\n",
    "# matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " calc_scores(matrix)\n",
    " \n",
    "{'recalls': array([0.31693989, 0.34710744, 0.28      ]),\n",
    " 'Precisions': array([0.28292683, 0.41176471, 0.2565445 ]),\n",
    " 'f1': 0.31587601668402826}\n",
    "'''\n",
    "\n",
    "def calc_scores(matrix):\n",
    "    Recalls = np.zeros(3)\n",
    "    for i in range(3):\n",
    "        Recalls[i] = matrix[i][i]/sum(matrix[i])\n",
    "    Precisions = np.zeros(3)\n",
    "    pred_sum = matrix.sum(axis=0)\n",
    "    for i, ps in enumerate(pred_sum):\n",
    "        Precisions[i] = matrix[i][i]/ps\n",
    "    f1_score = 2*Recalls.mean()*Precisions.mean()/(Recalls.mean()+Precisions.mean())\n",
    "    return {\n",
    "        \"recalls\":Recalls,\n",
    "        \"Precisions\":Precisions,\n",
    "        \"f1\":f1_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "predのキー\n",
    "dict_keys(['pred_train', 'pred_test', 'x_train', 'y_train', 'x_test', 'y_test'])\n",
    "'''\n",
    "\n",
    "def print_miss_pred(pred, test=True):\n",
    "    if test:\n",
    "        true_y = pred[\"y_test\"]\n",
    "        pred_y = pred[\"pred_test\"]\n",
    "        df     = pred[\"x_test\"]\n",
    "    else:\n",
    "        true_y = pred[\"y_train\"]\n",
    "        pred_y = pred[\"pred_train\"]\n",
    "        df     = pred[\"x_train\"]\n",
    "        \n",
    "    idx_arr = []\n",
    "    pred_judge=[]\n",
    "    true_judge=[]\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i]!=true_y.values[i]:\n",
    "#             print(pred[i], true_y.values[i])\n",
    "            idx_arr.append(i)\n",
    "            pred_judge.append(pred[i])\n",
    "            true_judge.append(true_y.values[i])\n",
    "\n",
    "    def print_str_label(num):\n",
    "        if num==0:return \"ニュートラル\"\n",
    "        if num==1:return \"悪口\"\n",
    "        if num==2:return \"皮肉\"\n",
    "        return np.nan\n",
    "\n",
    "    for i,idx in enumerate(idx_arr):\n",
    "        display(df.iloc[idx].content)\n",
    "        print('true label  *',true_judge[i] , (print_str_label(true_judge[i])))\n",
    "        print('pred label  *',pred_judge[i], (print_str_label(pred_judge[i])))\n",
    "        print(\"------------------------------------------------------------------------------------\")\n",
    "#     return idx_arr\n",
    "#     return pred_judge, true_judge\n",
    "# print_miss_pred(y_test, pred_test)\n",
    "# p,t = print_miss_pred(y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.to_csv('../data/clean/mount_data.csv', index=False)\n",
    "# df1.to_excel('../data/clean/mount_data.xlsx', index=False)\n",
    "# df1 = pd.read_excel('../data/clean/mount_data.xlsx')\n",
    "# df1 = df1.dropna()\n",
    "# df1[\"type\"]=df1.target\n",
    "# df1 = make_bad_feature(df1, badwordlist=badwordlist, positivelist=positivelist, hinikulist=hinikulist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1[df1.target==0].shape[0], df1[df1.target==1].shape[0],df1[df1.target==2].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_matrix = create_3x3_matrix(pred[\"y_train\"], pred[\"pred_train\"])\n",
    "# test_matrix  = create_3x3_matrix(pred['y_test'],  pred['pred_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_scores(train_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_scores(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print_miss_pred(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# predのキー\n",
    "# dict_keys(['pred_train', 'pred_test', 'x_train', 'y_train', 'x_test', 'y_test'])\n",
    "# '''\n",
    "\n",
    "# def print_miss_pred(pred, test=True, true_y=np.nan, pred_y=np.nan,df=np.nan):\n",
    "#     if test:\n",
    "#         true_y = pred[\"y_test\"]\n",
    "#         pred_y = pred[\"pred_test\"]\n",
    "#         df     = pred[\"x_test\"]\n",
    "#     else:\n",
    "#         true_y = pred[\"y_train\"]\n",
    "#         pred_y = pred[\"pred_train\"]\n",
    "#         df     = pred[\"x_train\"]\n",
    "\n",
    "\n",
    "#     idx_arr = []\n",
    "#     pred_judge=[]\n",
    "#     true_judge=[]\n",
    "#     for i in range(len(pred_y)):\n",
    "#         if pred_y[i]!=true_y.values[i]:\n",
    "# #             print(pred[i], true_y.values[i])\n",
    "#             idx_arr.append(i)\n",
    "#             pred_judge.append(pred_y[i])\n",
    "#             true_judge.append(true_y.values[i])\n",
    "\n",
    "#     def print_str_label(num):\n",
    "#         if num==0:return \"ニュートラル\"\n",
    "#         if num==1:return \"悪口\"\n",
    "#         if num==2:return \"皮肉\"\n",
    "#         return np.nan\n",
    "\n",
    "#     for i,idx in enumerate(idx_arr):\n",
    "#         display(df.iloc[idx].content)\n",
    "#         print('true label  *',true_judge[i] , (print_str_label(true_judge[i])))\n",
    "#         print('pred label  *',pred_judge[i], (print_str_label(pred_judge[i])))\n",
    "#         print(\"------------------------------------------------------------------------------------\")\n",
    "# #     return idx_arr\n",
    "# #     return pred_judge, true_judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/clean/mount_data.csv').dropna()\n",
    "df[\"comment_id\"] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize(text):\n",
    "#     return tokenizer.tokenize(text,wakati=True)\n",
    "# text=\"これは美味しいです\"\n",
    "# tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content = df1.content.values\n",
    "# target = df1.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nベクトル化\\n'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "'''\n",
    "# x_train,x_test, y_train, y_test = train_test_split(content, target, random_state=42)\n",
    "# print('binary')\n",
    "# vec = CountVectorizer(binary=True)\n",
    "# train_and_val(x_train, x_test, y_train, y_test, vec)\n",
    "\n",
    "# print('count')\n",
    "# vec = CountVectorizer(binary=False)\n",
    "# train_and_val(x_train, x_test, y_train, y_test, vec)\n",
    "\n",
    "# print('tfidf')\n",
    "# vec = TfidfVectorizer()\n",
    "# vectorize(x_train, x_test, y_train, y_test, vec)\n",
    "\n",
    "# print(\"bigram\")\n",
    "# vec = TfidfVectorizer(ngram_range=(1,3))\n",
    "# train_and_val(x_train, x_test, y_train, y_test, vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>mophologics_num</th>\n",
       "      <th>bad_per_mophologic</th>\n",
       "      <th>simple_bad_flg</th>\n",
       "      <th>target</th>\n",
       "      <th>hiniku_per_mophologic</th>\n",
       "      <th>simple_hiniku_flg</th>\n",
       "      <th>positive_per_mophologic</th>\n",
       "      <th>simple_positive_flg</th>\n",
       "      <th>comment_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ガイジ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>くどい</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>偽物　ただの釣り動画</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>振り付けダサイ</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>男きも</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>動画もいいな</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>3桁記念かきこ</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>鳥肌やばい</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>兄弟愛に泣いた</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>もう泣きそうなんだが</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2140 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         content  mophologics_num  bad_per_mophologic  simple_bad_flg  target  \\\n",
       "0            ガイジ                1                   1               1       1   \n",
       "1            くどい                1                   1               1       1   \n",
       "2     偽物　ただの釣り動画                6                   2               1       1   \n",
       "3        振り付けダサイ                2                   0               1       1   \n",
       "4            男きも                3                   0               1       1   \n",
       "...          ...              ...                 ...             ...     ...   \n",
       "2347      動画もいいな                4                   0               0       0   \n",
       "2348     3桁記念かきこ                5                   0               0       0   \n",
       "2349       鳥肌やばい                2                   0               0       0   \n",
       "2350     兄弟愛に泣いた                5                   0               0       0   \n",
       "2351  もう泣きそうなんだが                7                   0               0       0   \n",
       "\n",
       "      hiniku_per_mophologic  simple_hiniku_flg  positive_per_mophologic  \\\n",
       "0                         0                  0                        0   \n",
       "1                         0                  0                        0   \n",
       "2                         0                  0                        0   \n",
       "3                         0                  0                        0   \n",
       "4                         0                  0                        0   \n",
       "...                     ...                ...                      ...   \n",
       "2347                      0                  0                        1   \n",
       "2348                      0                  0                        0   \n",
       "2349                      0                  0                        0   \n",
       "2350                      0                  0                        0   \n",
       "2351                      0                  0                        0   \n",
       "\n",
       "      simple_positive_flg  comment_id  \n",
       "0                       0           0  \n",
       "1                       0           1  \n",
       "2                       0           2  \n",
       "3                       0           3  \n",
       "4                       0           4  \n",
       "...                   ...         ...  \n",
       "2347                    1        2347  \n",
       "2348                    0        2348  \n",
       "2349                    0        2349  \n",
       "2350                    0        2350  \n",
       "2351                    0        2351  \n",
       "\n",
       "[2140 rows x 10 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nagataeiki/opt/anaconda3/envs/learning/lib/python3.8/site-packages/pandas/core/frame.py:3990: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin\n"
     ]
    }
   ],
   "source": [
    "pred = train_and_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[592.   0.   0.]\n",
      " [  0. 741.   5.]\n",
      " [ 41.   0. 333.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recalls': array([1.        , 0.99329759, 0.89037433]),\n",
       " 'Precisions': array([0.93522907, 1.        , 0.9852071 ]),\n",
       " 'f1': 0.9673125359877756}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix=create_3x3_matrix(pred[\"y_train\"], pred[\"pred_train\"])\n",
    "print(matrix)\n",
    "calc_scores(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[155.   0.   0.]\n",
      " [  0. 184.   2.]\n",
      " [  4.   0.  83.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'recalls': array([1.        , 0.98924731, 0.95402299]),\n",
       " 'Precisions': array([0.97484277, 1.        , 0.97647059]),\n",
       " 'f1': 0.98242878020966}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix=create_3x3_matrix(pred[\"y_test\"], pred[\"pred_test\"])\n",
    "print(matrix)\n",
    "calc_scores(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning",
   "language": "python",
   "name": "learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
